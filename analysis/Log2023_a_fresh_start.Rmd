---
title: "Log2023"
output:
  workflowr::wflow_html:
              toc: true
              toc_depth: 4
editor_options:
  chunk_output_type: console
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, out.width = "50%")
```


```{css style settings, echo = FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 16px;
    border-left: 5px solid #eee;
}
```

**If any figures don't show, try opening in Safari.**

# Apr 26

## 1. Show top p of seg-based and peak-based

Add this figure to previous section [Try other CPM cutoff factors](#try-other-cpm-cutoff-factors).

- Top p's are bonferroni corrected by multiplying the number of cis SNPs of a group. 

- Only show groups with top p < 1e-3.


## 2. More figures of comparison between multi-segments-PCO and uni-merged-segments


### Compare nominal top p-values by multi-segments-PCO and uni-merged-segments

Add this figure to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).

Use **nominal top p**, w.o. bonferroni correction by multiplifying number of cis SNPs of groups. We wanted to look at this because we think cis regions should have same #independent SNPs. Not much difference with top p with bonferroni correction.


### Only show groups with large top p difference

i.e. log(topp_diff)>2.

Add this figure to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).


### What are these groups?

Add figures to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).


- Group size of seg/merged groups off diagonal line

- #Vars in cis of seg/merged groups off diagonal line




# Apr 19

## Quick summary

- Check peak width for marks

- Compare p-values by multi-segments-PCO and uni-merged-segments in terms of top p, small p, and all p.

- Not finish comparison in terms of cmerged_seg/csegment/cpeak-group. With questions.



## 1. Check peak width for marks

### Why?

To see what segment size should be used to cover a whole peak for different marks.


### Results

```{r out.width="40%", fig.cap="Figure: Peak width of marks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_plt_peak_width_H3K27AC.pdf", 'asset/2023/04_19_plt_peak_width_H3K4ME1.pdf', 'asset/2023/04_19_plt_peak_width_H3K4ME3.pdf', 'asset/2023/04_19_plt_peak_width_H3K36ME3.pdf'), error = FALSE)
```


### Observations

- For mark H3K27AC, the average peak width is ~1kb.

- Mark H3K36ME3 has very wide peaks.


## 2. Compare p-values by multi-segments-PCO and uni-merged-segments

### Look top p at all scenarios - seg size and cpm cutoff factor {#top-p-comparsion-multi-merged}

Last week, I compared top p for one scenario. See below for all scenarios across seg sizes and cpm cutoff factors.

```{r out.width="30%", fig.cap="Figure: Compare p of seg_multi_pco and seg_merged_uni in terms of top p of groups. Top p's are bonferroni corrected by multiplying the number of cis SNPs of a group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_1_plt_topp_multi_sum_chr20_avgcpmfct2_seg1.5kb.pdf", 'asset/2023/04_19_2_plt_topp_multi_sum_chr20_avgcpmfct2_seg2kb.pdf', 'asset/2023/04_19_3_plt_topp_multi_sum_chr20_avgcpmfct3_seg0.5kb.pdf', 'asset/2023/04_19_4_plt_topp_multi_sum_chr20_avgcpmfct3_seg1kb.pdf', 'asset/2023/04_19_5_plt_topp_multi_sum_chr20_avgcpmfct3_seg1.5kb.pdf', 'asset/2023/04_19_6_plt_topp_multi_sum_chr20_avgcpmfct3_seg2kb.pdf'), error = FALSE)
```


We also wanted to look at -

[Use nominal top p, w.o. bonferroni correction by multiplifying number of cis SNPs of groups. We wanted to look at this because we think cis regions should have same #independent SNPs. Not much difference with top p with bonferroni correction.](asset/2023/04_26_plt_topp_nominal_multi_sum_chr20.pdf)



Look into those seg/merged groups off diagonal line -

- [Only show groups with large top p difference, i.e. log(topp_diff)>2.](asset/2023/04_26_plt_topp_bigdiff_multi_sum_chr20.pdf)

- [Group size of seg/merged groups off diagonal line](asset/2023/04_26_plt_topp_bigdiff_group_size_multi_sum_chr20.pdf)

- [#Vars in cis of seg/merged groups off diagonal line](asset/2023/04_26_plt_topp_bigdiff_cissnp_multi_sum_chr20.pdf)




**Observations -**

- In terms of top p (with bonferroni correction on cis snps), seg_multi and seg_merged don't have much difference.



### Look all p from (SNP, group), not only just top p

No bonferroni correction just nominal p.

```{r out.width="30%", fig.cap="Figure: Compare p of seg_multi_pco and seg_merged_uni in terms of small p and all p of (SNP, seg group/merged group) pairs. Small p's show p < 1e-5. All p's show truncated QQ plot.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_1_plt_allp_multi_sum_chr20_avgcpmfct2_seg1.5kb.pdf", 'asset/2023/04_19_2_plt_allp_multi_sum_chr20_avgcpmfct2_seg2kb.pdf', 'asset/2023/04_19_3_plt_allp_multi_sum_chr20_avgcpmfct3_seg0.5kb.pdf', 'asset/2023/04_19_4_plt_allp_multi_sum_chr20_avgcpmfct3_seg1kb.pdf', 'asset/2023/04_19_5_plt_allp_multi_sum_chr20_avgcpmfct3_seg1.5kb.pdf', 'asset/2023/04_19_6_plt_allp_multi_sum_chr20_avgcpmfct3_seg2kb.pdf'), error = FALSE)
```

**Observations -**

- In terms of all p (without multiple testing correction), seg_multi is better than seg_merged only in case avgcpmfct3_seg2kb.



### Compare group in terms of csegment_group?

> Use the way how people find cpeak to find csegment_group. With multiple testing correction.

**Question -**

- Isn't this the same as [what I did](#top-p-comparsion-multi-merged) where I looked at top p (with bonferroni correction on cis snps)?

- Since last time we said what people want is csegment/cpeak_group, and given seg_multi and seg_merged are similar in terms of top p, should this be concerning?


## 3. Compare seg-based and peak-based in terms of csegment/cpeak_group

**Question -**

Same reason as above.




# Apr 05 & Apr 12

## Quick summary

- Updated figures and observations from last time, adding factor 1 and peak-based.

- Re-do segment-based by changing peak filtering from using average log2 CPM as cutoff to using average CPM.

- Tried using different segment sizes.

- Compared p-values of segment-multi PCO with segment-uni (merged reads from multiple segments).



## 1. Re-do peak filtering using average CPM, not log2 based

**Two changes on segment filtering based on cpm -**

1. Cutoff to be ave cpm, instead of ave log2 cpm as used in last time.

2. Use median across segments instead of mean, as large variation expected across segments. [Use mean of one seg across individuals, as similar count expected for individuals.]


- Should be adding the factor instead of multiplying. More stringent cutoff and less segments.


- Under CPM filtering cutoff, check segment numbers

```{r out.width="50%", fig.cap="Figure: How many segments are retained after removing segments based on average log2 CPM?", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_avgcpmfct.pdf"), error = FALSE)
```

- Under CPM filtering cutoff, check group size

```{r out.width="50%", fig.cap="Figure: Segment group size across various factors of average log2 CPM.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_group_size_avgcpmfct.pdf"), error = FALSE)
```


- Run all thing - Check p

```{r out.width="50%", fig.cap="Figure: P value distribution under various factors of log2 average CPM. Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_avgcpmfct.pdf"), error = FALSE)
```


```{r out.width="50%", fig.cap="Figure: QQ-plot of P values under various factors of log2 average CPM. I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_avgcpmfct_qqplot.pdf"), error = FALSE)
```


**Observation**

- I tried using mean of ave cpm as cutoff, too many segs were removed.

- More segments left.

- Use 2 or 3 to be comparable or better than peak based.

- Computation time on chr20: using 2 takes ~2h, 3 takes ~1h.

- P values under these factors not differ much, not as results from last time, because the number of tests do not differ much ...

- **Again, peak-based is the best in terms of QQ-plot, due to much less number of tests. Increase segment size?**



### csaw paper on filtering windows

- Check csaw's user guide for the histogram of CPM with their cutoff and background cutoff. They retain very few windows. (Page 25)


- Cutoff depends on mark binding site. Narrow v.s. Broad.

> Smaller minimum fold changes are recommended for diffuse marks where the difference from background is less obvious.




## 2. Use different segment sizes

### How?

Use 0.5kb, 1kb, 1.5kb, 2kb to define segment size.

Use factor 3 for all segment sizes.


### Results

- Check segment cpm distribution and numbers based on CPM filtering

```{r fig.cap="Figure: Use 0.5kb, 1kb, 1.5kb, 2kb to define segment size. With that, split chr20 into segments, and then apply cpm filtering using factor 3. (A) Log2(average cpm) distribution across segments under various segment sizes. (B) The number of retained segments after filtering segments based on (median of average cpm) times various factors.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_segsize.pdf"), error = FALSE)
```


- Check size of segment groups

```{r out.width="50%", fig.cap="Figure: Segment group size across various segment sizes after filtering segments using 3*median(average CPM).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_group_size_segsize.pdf"), error = FALSE)
```


- Check p

```{r fig.cap="Figure: P value distribution under various segment sizes after filtering segments using 3*median(average CPM). Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_segsize.pdf"), error = FALSE)
```


```{r fig.cap="Figure: QQ-plot of P values under various segment sizes after filtering segments using 3*median(average CPM). I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_segsize_qqplot.pdf"), error = FALSE)
```



### Try other CPM cutoff factors {#try-other-cpm-cutoff-factors}

- Why? Use various cpm cutoff for various segment sizes. Larger segments, more reads, higher CPM, higher average CPM. If using the same cpm cutoff factor as smaller segments, the cutoff can be much higher and more segments would be filtered out.


- Check size of segment groups

```{r out.width="50%", fig.cap="Figure: Segment group size across various segment sizes after filtering segments using various CPM factor cutoffes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_plt_seg_group_size_avgcpmfct_segsize.pdf"), error = FALSE)
```


- Check p

```{r fig.cap="Figure: P value distribution under various segment sizes after filtering segments using 3*median(average CPM). Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_p_avgcpmfct_segsize.pdf"), error = FALSE)
```


```{r fig.cap="Figure: QQ-plot of P values under various segment sizes after filtering segments using 3*median(average CPM). I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_p_avgcpmfct_segsize_qqplot.pdf"), error = FALSE)
```



```{r fig.cap="Figure: Top P value distribution. Top p's are bonferroni corrected by multiplying the number of cis SNPs of groups. Only show groups with top p < 1e-3.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_26_compare_topp_avgcpmfct_segsize.pdf"), error = FALSE)
```



- **Observations**

  - Segment size still smaller than peak width.
  
  - **Again, peak-based is the best in terms of QQ-plot, due to much less number of tests. Increase segment size?**




- Solve questions written on the paper sheet - on read counting & cpm cutoff for various segment size.


- Check if -p -reduce read1.bam` has same alignment as` -p -reduce -O`


- Read counting is problematic.
  
  - seg1kb, different assigned reads for two run
  
  - `count_based/seg_chr/seg1kb_chr20.saf`
  
  - `count_based/featurecounts/3_Counts_paired_leftmost_onlyread1.txt` v.s `count_based/featurecounts/Counts_paired_leftmost_onlyread1_seg1kb_chr20.txt`


-   Try size options, large or small, for current narrow peaks or future wide peaks. Check segment numbers, group size.




## 3. Merge reads across segments

See some intuitions from [reading below](#sum_reads_across_seg).


### How?

- Filter segments first.

- The total read counts across segs in a window.

- Same QC and normalizations.

- cis - 500kb. Probably more test than PCO.

2266 groups.


### Comparison

- Top p

- #cis SNPs tested for each group


```{r fig.cap="Figure: (A) Comparion of top p of each group for segment_multi and segment_sum. Top p was bonferroni corrected by the number of cis SNPs tested for the group. (B) Distribution of number of cis SNPs tested for each group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_multi_sum.pdf"), error = FALSE)
```



## 4. Ideas from reading

### Sum of reads for a peak v.s. slice the peak by windows/segments [@lun2016] {#sum_reads_across_seg}

If a region/peak is broad/diffuse, QTL effects on all parts of the peak are weak but consistent. Then summing of reads provides greater detection power for such regions, as large peaks can collect more read counts than small windows. And since each subinterval of the region has the same/positively correlated QTL effects, no benefit is gained from considering each subinterval separately with small windows.


### When is window-based strategy powerful - some intuitions

- When detecting complex DB events, use windowing to increase spatial resolution missed by peak calling -

> csaw was more powerful than other methods at detecting complex DB events, especially those involving changes in the width of a binding event.

> The relatively poor performance of peak-based methods can be attributed to the fact that each binding site is defined as a single peak by MACS or HOMER. 

> csaw is able to tile small windows across the binding site. Each window corresponds a different subinterval of the binding site, such that the magnitude of any changes in part of the site can be faithfully captured by a window.

In my case, also add a case of where intensity difference is low.

**This is actually different than our case, where we wanted the window size to be approximately peak size, so that a window group would contain multiple peaks to be jointly tested. However, the idea of csaw is to split a general complex peak to sub-intervals, each of which are captured by windows for increased resolution.**

- When the peak is narrow and easily identified, window-based strategy should have comparable power to peak calling.

> sharp peaks were easily identified by the peak calling software. In this case, windowing did not provide any useful gain in spatial resolution. Nevertheless, csaw still returned the same performance curve as the best peak-based methods.

**In our case, our idea should be more powerful than peak calling even when the peaks are well-defined, since we test multiple peaks jointly.**



## Choose ways to cluster windows/segments into groups





# Mar 29

## Quick summary

- Re-do segment-based by adding cpm filtering on segments.


## 1. Re-thinking of segment-based idea

### Segment-based for narrow peaks

-   Goal: to skip peak calling

-   Illustration figure - ideal case

    We want segment size to be peak-width to include multiple peaks together.

### Segment-based for braod peaks

-   Goal: to compensate peak calling

-   Illustration figure - ideal case

    We want segment size to be smaller than peak-width to split a broad peak to multiple segments.



## 2. Add cpm filtering on segments and re-do segment-based

### How?
  
  Average log2 CPM for each segment across samples. Mean of average log2 CPM. Add a factor.


### Under CPM filtering cutoff, check segment numbers

```{r out.width="50%", fig.cap="Figure: How many segments are retained after removing segments based on average log2 CPM?", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_plt_seg_avgcpmfct.pdf"), error = FALSE)
```

### Under CPM filtering cutoff, check group size

```{r out.width="50%", fig.cap="Figure: Segment group size across various factors of average log2 CPM.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_plt_seg_group_size_avgcpmfct.pdf"), error = FALSE)
```


### Run all thing

```{r out.width="50%", fig.cap="Figure: P value distribution under various factors of average log2 CPM. Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_compare_p_avgcpmfct.pdf"), error = FALSE)
```

See histogram for peak-based and factor 2 and 3 [here](asset/2023/03_29_compare_p_avgcpmfct_sub.pdf).


```{r out.width="50%", fig.cap="Figure: QQ-plot of P values under various factors of average log2 CPM. I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_compare_p_avgcpmfct_qqplot.pdf"), error = FALSE)
```


**Observation**

- Use factor 3, in terms of,
  
  - Absolute number of small p values. Compare to factor 4 and 2.
  
  - Density of small p values. Compare to factor 4 and 2.
  
  - Computation speed.


**Updated Observation**

- Add segment-based using factor 1 and peak-based.

- Peak-based is comparable to segment-based using factor 2 and 3, in terms of absolute number of small p values.

- **But Peak-based is the best in terms of qq plot of all p values.**
  
  - This is due to though peak-based is comparable to segment-based using factor 2 and 3, it has much fewer tests.
  
  - Increase segment size?



### Issues

I can't do the following to-do as mentioned last time,

- cdf and histogram of all pvalues
  
  Looks exactly same and highly overlapped under various factors of average log2 CPM. Because most p values are large, so those small p values are only a few and their differences don't matter much when plotting all p values.

- scatter plot
  
  Impossible to plot all p values on a scatter plot. Instead, I plotted the QQ plot of all pvalues. Not sure if it is equal.



## 3. Ideas from reading

### 1kb is not wide as segment size for broad peaks

-   From literature, they typically use 1kb as bin size for broad peaks.

-   We don't need higher resolution for wide domain/peak so we actually want the segment to be wide.

-   If we apply this idea to narrow peaks - cut the peak to segments instead of joint multiple peaks, we need narrower segment.

### Why avoid peak calling? [@lun2016]

-   It can be problematic even for narrow peaks.

> To avoid the biases and loss of resolution associated with peak calling, the software packages USeq ([13](javascript:;)), diffReps ([14](javascript:;)) and PePr ([15](javascript:;)) have implemented windowing strategies.

-   Peak calling followed by other analysis, e.g. DB, can loss error control. So use a sliding window (de novo detection) instead.

    -   Window-based strategy has well controlled error rates - unlike peaks (peak calling and DB on the same dataset), windows are defined independently from the data.

-   In my case, add - peak calling for broad peaks

-   In my case, add - no need to learn peak calling



# Mar 08 & March 15 & March 22

## Quick summary

- Figured out Ben & Carlos's steps on their histone peak QTLs we used previously.

- Finish count-based / segment-based version of PCO.


## 1. What they did to process data for peak QTLs

To work on count based QTL mapping, I need to first figure out the exact steps Ben & Carlos's did to process the histone data and peak QTL mapping, in order to make consistent window-based and count-based QTL mapping. Below is a mindmap of steps, QC, normalization etc. of Ben & Carlos did to generate peak QTLs.

```{r out.width="100%", fig.cap="Figure: What Ben & Carlos did to process data.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_Histone_mark_reads.pdf"), error = FALSE)
```


## 2. Count based - Processing data

- Why?

- How? A few things to be changed
  
  Make pre-processing data consistent with window-based, except -
  
  - Redefine segments on genome as .saf rather than peak calling regions.
  
  - Adaptations to QC
    
    - Remove segments without any reads
    
    - Remove segments without reads in 1-?% individuals (I tried 100%, 50%)


### Split chr's by segments

- How?
  
  Split the chromosome from 0 to chromosome length by a segment size - 1kb.

- Number of segments across chr

```{r out.width="50%", fig.cap="Figure: Number of split segments compared to the called peaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_num_features.pdf"), error = FALSE)
```


### Count reads within each seg

- 4 histone marks (by ChIP-seq or CutAndTag) are all paired-end reads.


- Count by paired-end
  
  ~~No `-p`. Reads instead of paired-end fragments will be counted.~~
  
  Use `-p`. [Count fragment instead](https://support.bioconductor.org/p/67534/).


- Ways to count a read overlapped with multiple features
  
  [At first, I didn't think through this until I observed many unassigned reads due to Unassigned_Ambiguity.]
  
  - ~~Use `-p -O` to assign the read (1) to all overlapped features.~~ [FEATURECOUNTS PAPER SUGGESTION ON USING _O]

  - ~~Use `-p --largestOverlap` to assign the read (1) to the feature that has the largest number of overlapping bases.~~
  
  - ~~Use `-p --fraction -O` to assign a fractional count (1/y, where y is the total number of features overlapping with the read) to all overlapped features.~~
  
  - Use `-p --read2pos 5`. Think a fragment as a whole, and take the left-most base.
  
  - ~~Use `--read2pos 5` to reduce the read to an end base (as said by Yang, left-most-read-base to count in bam file, take just one base, to avoid that one read in multiple regions) and count the reduced single base.~~
  
  - Use `-p --read2pos 5 single_paired_read1_*.bam`. Use paired-end, but only uses read 1. Reduce the read to left-most-base.


```{r}
feature_counts_mode <- data.frame(
  "flag" = c(
    "-p",
    "-p -O",
    "-p --largestOverlap", 
    "-p --read2pos 5", 
    "--read2pos 5", 
    "-p --read2pos 5 single_paired_read1_*.bam",
    
    "-p --read2pos 5 -O",
    "-p --read2pos 5 --largestOverlap"
  ),
  "interpretation" = c(
    "paired-end, ignore overlap count",
    "paired-end, assign overlap count to all regions",
    "paired-end, assign overlap count to region with largest overlap",
    "paired-end, reduce read to left-most-base",
    "single-end, reduce read to left-most-base",
    "paired-end, reduce read to left-most-base, but use only the first read",
    
    "paired-end, reduce read to left-most-base, assign overlap count to all regions",
    "paired-end, reduce read to left-most-base, assign to largest overlap"
  )
)

knitr::kable(feature_counts_mode)
```


```{r out.width="50%", fig.cap="Figure: (un)Assigned reads under various counting modes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_count_mode.pdf"), error = FALSE)
```


**Observation**

- Unassigned reads under `-p --read2pos 5 single_paired_read1_*.bam`.
  
  - These unassigned reads due to ambiguity are only for one individual.
  
  - Weirdly, if I do read counting for only this individual, there is no unassigned reads.
  
  - If I count read all individuals together and with `-R` to output the detailed (un)assignment of each read, there is no unassigned reads again. So I couldn't check exactly which reads were unassigned for this individual.
  
  - I used the above read counting results.



- Why both single-end and paired-end reads occur in one bam file?
  
  Paired-end sequencing. But those single-end reads are not aligned to ref genome.




**A few numbers - raw counts**

- For current exploratory phase, I only run chromosome 20, which was split to 64,444 1kb-segments.
  
  - 62,910 (~97.62%) segments with at least one read in one individual.
  
  - %individuals without any reads


```{r out.width="30%", fig.cap="Figure: Raw counts across segments.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_seg_count.pdf", "asset/2023/03_08_seg_count_zoom.pdf"), error = FALSE)
```


```{r out.width="30%", fig.cap="Figure: % Individuals with nonzero raw counts.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_perct_ind.pdf"), error = FALSE)
```


- I feature count 2337 peaks on chr20, and compared the count summary with segment-version on chr20. A few potential questions needed further understanding -

  - In featureCounts, unassigned reads due to Unassigned_Duplicate, Unassigned_NoFeatures, many Unassigned_Ambiguity.
  
  - There are many Unassigned_Ambiguity, because reads can fall between adjacent segments. Solution: use `--read2pos` to count only the left-most-base.




### QC & Normalization

- Remove segments without any reads for any individuals.

- Filter segments by proportion of samples with non-zero reads - 100%, 50%.

- Regular standardization & qqnorm way v.s. leafcutter way.


### Covariates

Temporary workaround - Use PC's of peaks.


### QTLTools

Chr20 for now. All cis-SNPs around 500kb of each segment.



## 3. Count based - Perform PCO

### Define segment groups

- Window size - 10kb

- Segment size - 1kb


```{r out.width="50%", fig.cap="Figure: Segment group size under 10kb window size across prop_nonzero (1, 0.5).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_seg_group_size.pdf"), error = FALSE)
```


**Observations** -

- #groups used for PCO (remove those groups with 1 seg)

- group size v.s. sample size (72)
  
  Group size controlled under 10, for seg_size = 1kb, window_size=10kb


- Is 1kb too wide for segment size?


### Perform PCO

- P for across prop_nonzero (1, 0.5) & compare to peak group.

- I expect seg_pco to be similar to peak_pco, as these results are from mark H3K27ac with narrow peaks.
  
  - I expect seg_pco to be powerful for marks with broad peaks.


```{r out.width="50%", fig.cap="Figure: Comparison of small p of segment group size under 10kb window size across prop_nonzero (1, 0.5).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_smallp.pdf"), error = FALSE)
```



# Feb 24 & Feb 29

## Quick summary

- Locus zoom of a region to visualize PCO and MinP associations

- Genome track by genotype



## 1. Compare p's of specific association pairs by MinP and PCO

Change the way of visualization -

```{r out.width="50%", fig.cap="Figure: To compare MinP and PCO.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_24_plt_small_p_pco_acat_methods_diag_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```



## 2. Locus zoom of (a peak group, cis region)

### Why?

Significant PCO associations, weak ACAT associations.

For follow up analysis, e.g. coloc with traits.


But since we are not comparing to ACAT associations, is this analysis still necessary? (Does it really make sense to compare with MinP?)

For coloc purpose, improve detection of mediate effects. How does it help with coloc power? or anything else?



### How?

For a peak group, cis region. Two methods: PCO & MinP.


- Issues
  
  - ~~`locuscomparer` not available to install on midway3.~~
  
  - ~~Convert SNP position to rsid.~~
  
  - **~20% SNPs no rsid?**



### Example regions

```{r out.width="30%", fig.cap="Figure: Locus compare MinP and PCO.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_24_G55137_chr20_2_peaks_0_4588_snps_10kb_.pdf"), error = FALSE)
```


- To select regions we want?


## 3. Genometracks by genotype

### Issues I ran into

- Use the new main function

- Use the wrong flag - unknown snp led to wrong genotype group

- Use the correct template
  
  `GeneralPurposeColoredByGenotype.ini`
  
  `GeneralPurposeColoredByGenotypeWithPerIndCoverage.ini`

- Correct template
  
  Change to the correct template.
  
  Minor - change the y max value to `PerGroupMaxPerInd`


### Example regions

```{r out.width="50%", fig.cap="Figure: Genome tracks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/1.pdf"), error = FALSE)
```

[Format 1](asset/2023/1.pdf)

[Format 2](asset/2023/2.pdf)


- To select regions we want?



## 4. Ideas from reading

- Define sliding windows with skip
  
  https://doi.org/10.1038/ng.2671 NA Something I learned that can be used in my cQTL work - Define sliding windows with skip by sliding the window based on both (1) sliding across at least one peak (the current way), (2) skip a gap window. Adding a gap sliding distance can decrease the degree of overlapping between two adjacent peak groups and reduce the number of tests. Or to be more precisely, use an overlap fraction.

- The idea of using overlap fraction to merge our significant peak groups.




# Feb 17

## Quick summary

- Evaluate PCO_ACAT

-  Apply PCO_ACAT to all chr's and window sizes of sliding windows with the goal to analyze data

- Thoughts & insights on previous results after reading ACAT more carefully



## 1. Evaluate PCO_ACAT

On non-overlapping windows as described in [previous progress](#non_overlapping_window).


### v.s. PCO

with the goal to see if PCO_ACAT works.
  
  - Compare P value distribution
  
```{r out.width="50%", fig.cap="Figure: To compare PCO and PCO_ACAT. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_15_plt_compare_small_p_pco_acat_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```

  - A more rigorous way to compare distributions?
  
  - Compare small p's of window sizes
  
  [Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.](asset/2023/02_15_plt_compare_small_p_pco_acat_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Compare specific association pairs
  
  [Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_15_plt_compare_small_p_pco_acat_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Computation time



### v.s. ACAT/MinP

with the goal to see if there is any improvement by PC-based method.

  - Compare P value distribution
  
```{r out.width="50%", fig.cap="Figure: To compare PCO_ACAT and ACAT?MinP. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_15_plt_small_p_pco_acat_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


  - Compare small p's of window sizes
  
  [Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.](asset/2023/02_15_plt_small_p_pco_acat_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Compare specific association pairs
  
  [Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_15_plt_small_p_pco_acat_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Computation time



## 2. Apply to all chr's and window sizes of (~~non-overlapping~~ / sliding windows) to analyze data

- Done.

- Computation time
  
  For $22\times9\times2$ ...



## 3. Thoughts & insgihts after read ACAT more carefully

Thoughts on previous results/observations/questions/concerns -

- Why did we observe similar p value distribution by ACAT and MinP (corrected by Bonferroni)
  
  As we discussed in ACAT paper JC, ACAT can be dominated by the very small p values.
  
  MinP corrected by Bonferroni and MinP with p values calculated by computational heavy permutation are similar.


- Why did we observe less improvements by PCO than ACAT/MinP than expected?
  
  - ACAT/MinP is not a good/common standard to compare with (as said by Yang), as (1) it is already powerful, (2) it is not what we wanted to improve on.
  
  - We should compare with univariate methods, which is commonly used and less improved and less powerful.
  
  - Not to compare the number of SNPs, as not significant biological meaning and hard to implement. Instead, we can use other ways, e.g. if improved coloc signals with traits, etc.




# Feb 08

## Quick summary

- Tested (SNP, peak group) of groups defined by non-overlapping windows.


## 1. Groups defined by non-overlapping windows {#non_overlapping_window}

### Why? (discussion on slack)

We observed many improved associations of PCO than ACAT/MinP in [previous section](#p_distribution_across_methods_and_window_sizes). One potential issue is these improved associations could possibly come from a small set of associations, due to many repetitive peaks & SNPs by sliding window, which appears to be a large set of associations.

So, we need to look into the case using non-overlapping windows, just to make sure the PCO improvement over minP is still there after avoiding repetitive counting of associations.


- Four points we discussed in Tuesday's meeting
  
  - Why coloc style and MACS2 style not work in this case?
    
    Because these two generate noncontinuous genomic regions, whereas what we need is to divide the whole genome into non-overlapping chunks.
  
  - Why would simple useage of non-overlapping windows not make sense in final version results? 
    
    Because choosing the start and end of the dividing window seems arbitrary.
  
  - It only makes sense if we want to take a rough look at PCO v.s. ACAT/MinP to avoid repetitive counting of signals in preliminary results.
  
  - To get final results, we should go back to sliding window + MACS2 merge.
    
    Calculate p-value for groups by sliding window, then merge. Maybe then test again to obtain updated p for merged group?


### How?

- Define non-overlapping windows
  
  Dividing the genomic locations starting from 0 into non-overlapping windows of a given window size.


### Results

- Compare small p's of three methods - Overall summary figures
  
  - Panel B shows the advantage of PCO persists under window size 25kb or smaller.
  
```{r out.width="50%", fig.cap="Figure: To compare three methods under non-overlapping windows. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_08_nonoverlap_window_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


- Compare small p's of three methods - Scatter plot
  
  **This is an important figure, but it's too large to show explicitly.**
  
  - For a pair of (SNP, group), PCO improves p-value than ACAT/MinP under window size 25kb or smaller.
  
  - For pair of (SNP, group) with p around 1e-5 by ACAT/MinP (i.e. the middle part), some pairs have improved p by PCO. (These pairs are likely the additionally identified signals by PCO.)
  
  - For pair of (SNP, group) with small p by ACAT/MinP (i.e. the right part) ...
  
  - PCO p in large, middle, and extreme small window sizes ...

[Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_08_nonoverlap_window_plt_small_p_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}


- Compare small p's of window sizes
  
  - PCO better or ACAT/MinP worse?

```{r out.width="50%", fig.cap="Figure: To compare window sizes under non-overlapping windows. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_08_nonoverlap_window_plt_small_p_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


# Feb 01

## Quick summary

- Compare small p, instead of top p, across three methods & window sizes

- Try even more extreme window sizes

- Example associations (by R not genome tracks)


## 1. Compare methods and window sizes using small p rather than top p

### Why


### How?

- Available results
  
  Methods - ACAT, MinP, PCO.
  
  Window size - 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  Chr - 20, 21, 22.

- Small p value cut off: 1e-5
  
  For a pair of (SNP, group), keep its association for comparing  if p by at least one method (ACAT, MinP, PCO) < 1e-5.


### Results

1. Compare small p's of three methods

[See below section for updated results]

**Observation**

- Why the density line of PCO and minP under 10kb look so different from the density lines below?
  
  It's because the smoothing algorithm to estimate the line for "density" (Figure C) and "histogram" (Figure A) is different. So the two lines have subtle difference.
  
  To avoid this, I changed the visualization from using a line of histogram (Figure A) to using histogram itself (Figure B).

- Figure B shows that PCO has smaller P's than MinP under 10kb window.



2. Compare small p's of window sizes

[See below section for updated results]


## 2. Try even more extreme window sizes

### Why


### How?

- Available results

  Methods - ACAT, MinP, PCO.
  
  Window size - **1kb, 2.5kb, 5kb**, 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  Chr - 20, 21, 22.

### Results {#p_distribution_across_methods_and_window_sizes}

- Compare small p's of three methods

```{r out.width="50%", fig.cap="Figure: To compare three methods. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```

- Compare small p's of window sizes

```{r out.width="50%", fig.cap="Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


- Aggregate all p values across chr's & window sizes and calculate stats: #groups, #tests

```{r out.width="40%", fig.cap="Figure: ", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_all_p_stats_H3K27AC_windowall_cis500kb_chr20-22.pdf"), error = FALSE)
```

  - Number of groups decreases as window size decreases
  
  - Number of (SNP, group) tests appears as U-shape


- Use a lower p cutoff
  
  P values lower than 1e-8, 1e-10 will be included.

```{r out.width="50%", fig.cap="Figure: LEFT: P cutoff 1e-8. RIGHT: P cutoff 1e-10.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22_pthre1e-08.pdf", "asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22_pthre1e-10.pdf"), error = FALSE)
```


**Observation**



## 3. Example associations to visualize P_pco and P_acat

### Goal

"For example, pick an example where PCO improved pvalue and pick another example where PCO doesn't improve pvalue?"


- ~~sashimi plots~~

- GenometracksByGenotype - pyGenomeTracks by genotype
  
  (Not doable yet)

### Another way

- Criteria to choose (SNP, group) to visualize for PCO and ACAT
  
  - Enough large difference: -log(P_pco/P_acat) > 5
  
  - At least one weak association: max(P_pco, P_acat) > 1e-5
  
  - Non-inf values: Non-zero P_pco


- Window - 100kb; Chr - 20-22


```{r out.width="20%", fig.cap="Figure: ", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_eg_H3K27AC_window100kb_cis500kb_G58821_22-21484558-CT-C_7_0_5.pdf", "asset/2023/02_01_eg_H3K27AC_window100kb_cis500kb_G57611_21-8836656-C-CAA_32_0_-5.pdf"), error = FALSE)
```



# Jan 25

## Quick Summary

- Test peak group defined by smaller window sizes using ACAT, minP, PCO.



## 1. Try smaller window sizes

### Why?

- We observed from last week's results that, it seems that PCO's p move toward ACAT/minP p when window sizes decrease.

- Groups of smaller window sizes that have multiple peaks tend to have physically closer peaks, thus more shared genetic control.


Therefore, we wanted to check if that pattern persists under smaller window sizes. So, I tried extreme window sizes, 10kb, 25kb, 50kb.


### How?

- Window sizes
  
  10kb, 25kb, 50kb, 100kb, 260kb, 500kb.


- Test groups with size > 1
  
  Smaller window sizes can have less groups tested.


- Test overlapped cis-SNPs within 500kb of peaks


- Available results
  
  window size - 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  chr - 20, 21, 22.


### Results

- Compare methods under same window size

```{r out.width="50%", fig.cap="Figure: Scatter plot of top p by three methods under same window size on chr21. x-axis: Each peak group. y-axis: -log10(P). Color show methods. Panel show window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_methods_scatter_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```


```{r out.width="50%", fig.cap="Figure: Distribution density of top p by three methods under same window size on chr21. x-axis: -log10(P). y-axis: density of peak group with corresponding P. Color show methods. Panel show window sizes. Same total number of groups within each panel.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_methods_density_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```

  We observe that PCO seems to similar or even more small p's under smaller window sizes. The question is - Is it because PCO under small windows better or ACAT/minP worse?



- Compare window sizes of same method

(more complicated as different numbers of groups tested)
  

```{r out.width="50%", fig.cap="Figure: Distribution of top p across window sizes by same method on chr21. x-axis: -log10(P). y-axis: (A) density, (B) number of peak group with corresponding P. Color show window sizes. Panel show methods. (C) Different numbers of groups (size > 1) tested for window sizes in each panel.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_windows_density_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```


Q - Larger window, higher proportion of small p, for ACAT/minP not pco, why?


- A fair way to compare window sizes?



- Top p of matching groups by three methods across window sizes


- Others

  - Group size tested

  - Number of cis-SNPs tested


## 2. PCO + ACAT




# Jan 18

## Quick Summary

- Compare across window sizes

- PC-based test on (SNP, peak group)



## 1. Determine window size

### Use all p not just top-p

- Compare p using ACAT and minp

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```


- Compare p by ACAT across window sizes (different total number of tests)

```{r out.width="60%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_window_size_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Distribution of small p under same number of peaks in group & same number of cpeaks in group

  small_p_thre <- 1e-8

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Percentage of cPeaks in group with small p under same number of peaks in group & same number of cpeaks in group

  small_p_thre <- 1e-8

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_perct_cpeak_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Number of groups

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_group_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```

- Number of cis-SNPs

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_cis_snp_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


## 2. Determine test

### PC-based

- phenotype

- genotype

- covaraites

  H3K27AC: 14 PCs


- Sigma
  
  Number of peaks v.s. number of samples (73)


- $\lambda>0.1$


- Available results
  
  Window size: 100kb, 250kb, 500kb.
  
  Chr: 21, 22.

- Comparison of top p across three methods

  - Scatter plot

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```
  
  - Distribution of top p

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_density_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```

  - Top p v.s. group size

```{r out.width="80%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_on_num_peaks_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```


## 3. Compare multi-cQTLs with uni-cQTLs

After discussion on slack, we decided **not to use uni-cQTLs as a comparison metric for now**. Reasons - 

- Comparison with uni-cQTLs not necessary in the long run for biological interpretations.

- Comparison with minp is sufficient for now

- Other ways for comparison of multi-cQTLs on top of the # of significant SNPs



# Jan 11

## Quick Summary

- Make the pipeline automatic.

- Tested (SNP, peak group) by ACAT at 100kb, 250kb, 500kb window size.

- Compare multi-cQTLs across window sizes and ~~with uni-cQTLs~~.


## 1. Define peak groups under different window sizes and test (SNP, peak group)

Last time, I tested (SNP, peak group) of peak groups defined by 500kb window sizes using SNPs within 500kb of peak group.

This time, I tried various window sizes, including 100kb, 250kb, 500kb.


### How?

- Peaks are considered as a peak group using a sliding window of sizes 100kb, 250kb, 500kb.

- Use 500kb as the cis distance to search for the cis-SNPs of each individual peaks in the group, then tested the overlapped SNPs across all peaks in the group. [Note: we discussed on slack to use 500kb as cis distance for all window sizes.]


```{r out.width="40%", fig.cap="Figure: Choose cis distance for different window size.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_choose_cis_dis.jpeg"), error = FALSE)
```


- ACAT test.


### Numbers

Use a table or histogram ...


### Results

- Number of peaks in groups

```{r out.width="20%", fig.cap="Figure: Number of peaks in peak groups defined by different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_peaks_in_group_H3K27AC_window100kb.pdf", "asset/2023/01_11_peaks_in_group_H3K27AC_window250kb.pdf", "asset/2023/01_11_peaks_in_group_H3K27AC_window500kb.pdf"), error = FALSE)
```


- Number of peaks in groups colored by cPeaks (uni)

  [Note: as we discussed on slack, I used the results of cPeaks within 500kb cis distance.]

```{r out.width="30%", fig.cap="Figure: Number of peaks in peak groups defined by different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window100kb_cpeak500kb.pdf", "asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window250kb_cpeak500kb.pdf", "asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window500kb_cpeak500kb.pdf"), error = FALSE)
```


- Peak groups on chr

[100kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window100kb.pdf)

[250kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window250kb.pdf)

[500kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window250kb.pdf)


- Number of cPeaks in peak groups

[100kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window100kb_cpeak500kb.pdf)

[250kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window250kb_cpeak500kb.pdf)

[500kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window500kb_cpeak500kb.pdf)

- Distribution of the top p-value of a peak group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group v.s. number of peaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```


- Top p of a peak group v.s. number of cPeaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group on chromosomal position

```{r out.width="35%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group on chromosomal position v.s number of cPeaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group v.s chromosomes

[100kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window100kb_cis500kb.pdf)

[250kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window250kb_cis500kb.pdf)

[500kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window500kb_cis500kb.pdf)


- Top p of a peak group v.s. the number of peaks in the group

[100kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window100kb_cis500kb.pdf)

[250kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window250kb_cis500kb.pdf)

[500kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window500kb_cis500kb.pdf)


## 2. Compare results across window sizes

I compared the results of peak groups defined by different window sizes in terms of (1) cQTLs (2) peak groups.


### Top p-value distribution across window sizes

```{r out.width="50%", fig.cap="Figure: Top p-vaue of a peak group across window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_window_size_H3K27AC_cis500kb.pdf"), error = FALSE)
```


### Number of significant cQTLs across window sizes

- How?

  - Use 1e-10 as the uniform p-value cutoff across window sizes.
  
  - Unique cQTLs for each group


Define significant cQTLs under same cutoff, as (1) same number of peak groups, (2) same cis distance used to search for SNPs to be tested.

- But not same number of SNPs tested?


```{r out.width="30%", fig.cap="Figure: Number of cQTLs across window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_cqtl_window_size_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


### cQTLs overlap across window sizes

- Use 1e-10 as the uniform p-value cutoff across window sizes.

```{r out.width="40%", fig.cap="Figure: Overlaps among cQTLs of different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_cqtl_overlap_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


- Observations

1. Most are shared.

2. 100kb some specific cQTLs?


- Missed cQTLs v.s. distance to their target peak groups

  Question to ask - Are the missed cQTLs those which are distant to their target peak groups, therefore, were not considered for association tests? Or is it because true higher power?

```{r out.width="40%", fig.cap="Figure: Window-size-specific cQTLs v.s. their distances to target peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_window_spec_cqtl_dist_group_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


### In terms of peak groups




## 3. Compare multi-cQTLs with uni-cQTLs


**Questions?**




# Dec 21

## Quick Summary

- Ran associations (by ACAT) between SNPs and peak groups using cis-window 1Mb.

- Looked at the distribution of p-values.



## 1. Update: Test a SNP and a group of adjacent peaks by ACAT

### Updates

- For each peak group, test its association across all overlapped SNPs (SNPs with cis-cQTL associations with all peaks in the group). ~~<u>**[Here I used the 100kb cis-cQTL]**</u>~~ <u>**[Use 1Mb cis-cQTL]**</u>


- For now, I only looked at the the peaks groups,
  
  - ~~where none of the peaks have significant cis-cQTLs <u>**[Here I used the 100kb cis-cQTL]**</u>~~ Run across all peak groups no matter how many significant cis-cQTLs they have.
  
  - which have more than 1 peak
  
  - of mark H3K27AC


- Except peak groups on chr1.


### Results

- Look at the distribution of top p-values of peak groups.

```{r out.width="30%", fig.cap="LEFT: Distribution of the top p-value (by ACAT and minp_adjusted) across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_density_H3K27AC.pdf"), error = FALSE)
```


- Look at the distribution of top p-values of peak groups on the size of peak groups and chromosomes.

```{r out.width="40%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_on_num_peaks_H3K27AC.pdf", "asset/2022/12_21_plt_top_p_peak_group_on_chr_H3K27AC.pdf"), error = FALSE)
```


- Distribution of top p-values on chromosomal position.

```{r out.width="60%", fig.cap="Distribution of the top p-value across peak groups on chromosomal position.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_manhattan_H3K27AC.pdf"), error = FALSE)
```


- Top p values of a peak group v.s. the number of peaks?

```{r out.width="50%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group. Color: the number of peaks in a peak group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_peaks.pdf"), error = FALSE)
```


- Top p values of a peak group v.s. the number of peaks with cQTLs?

  - .. and a more detailed zoom-in on chromosomal position given below

```{r out.width="50%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group that have cQTLs. Color: the number of peaks in a peak group that have cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_w_cqtl.pdf"), error = FALSE)
```

```{r out.width="70%", fig.cap="A more detailed zoom-in. Top p-values across peak groups on chromosomal position, grouped and colored by #peaks with uni-cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_manhattan_cqtl_H3K27AC.pdf"), error = FALSE)
```


- Compare the uni-cQTLs and multi-cQTLs of a peak group




~~### Numbers

Total peak groups: 100858

Peak groups on chr1: 10038

Peak groups on chr2-chr22: 90150 (90787, 90166)


Peak groups with only 1 peak: 26458

~~



# Dec 14

## Quick Summary

- Run ACAT to test associations between (SNP, adjacent peak group) for mark H3K27AC.


## 1. cQTL of peaks with cis-window of 1Mb

[Waiting for Carlos to run this step for me.]


## 2. Adjacent peaks as peak groups

### How?

- Sliding window of length 500kb.

- Start with a peak, extend from its start position to a 500kb window, include all peaks in this window as a peak group.

- Slide to next peak.


### Look into peak groups

- Number of peak groups in total
  
  There are 100,858 peak groups in total. 
  
- Number of peaks in each group

```{r out.width="30%", fig.cap="How many peaks are included in the preak groups? x-axis: the number of peaks. y-axis: the number of peaks groups with the corresponding number of peaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_in_group_H3K27AC.pdf"), error = FALSE)
```

- For peak groups with the same number of peaks, how many peaks have cQTLs? <u>**[Here I used the 100kb cis-cQTL]**</u>

```{r out.width="30%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group that have cQTLs. Color: the number of peaks in a peak group that have cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_in_group_w_cqtl_H3K27AC.pdf"), error = FALSE)
```


- Number of peaks with/without cQTLs in each group <u>**[Here I used the 100kb cis-cQTL]**</u>

```{r out.width="30%", fig.cap="How many peaks within a peak group have cQTLs? x-axis: the number of peaks with cQTLs. y-axis: the number of peak groups that have corresponding cPeaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_w_cqtl_in_group_H3K27AC.pdf"), error = FALSE)
```


## 3. Test a SNP and a group of adjacent peaks by ACAT

### How?

- For each peak group, test its association across all overlapped SNPs (SNPs with cis-cQTL associations with all peaks in the group). ~~<u>**[Here I used the 100kb cis-cQTL]**</u>~~ <u>**[Use 1Mb cis-cQTL]**</u>


- For (peak group, SNP), test by ACAT, a method to combine p-values.
  
  - As a comparison, I also calculated the adjusted minp, which $=min\{p_{snp, peak_1}, \dots, p_{snp, peak_k}\} \times k$, where $k$ is the number of peaks in the group.


- For now, I only looked at the the peaks groups,
  
  - ~~where none of the peaks have significant cis-cQTLs <u>**[Here I used the 100kb cis-cQTL]**</u>~~ Run across all peak groups no matter how many significant cis-cQTLs they have.
  
  - which have more than 1 peak
  
  - of mark H3K27AC


### Results

- There are 25,853 peak groups considered for association test.

- 3,450 peak groups have at least one overlapped SNPs. <u>**[Here I used the 100kb cis-cQTL]**</u>

So, now I have ACAT p-values (and adjusted minp) for peak groups across their overlapped SNPs. I take the minimum p-value for a peak group across the overlapped SNPs as the top p-value for the peak group.

- Look at the distribution of top p-values of peak groups.

```{r out.width="30%", fig.cap="LEFT: Top p-value (by ACAT and minp_adjusted) across peak groups. RIGHT: Distribution of the top p-value across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_top_p_peak_group_H3K27AC.pdf", "asset/2022/12_14_plt_top_p_peak_group_density_H3K27AC.pdf"), error = FALSE)
```

- Look at the distribution of top p-values of peak groups on the size of peak groups and chromosomes.

```{r out.width="40%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_top_p_peak_group_on_num_peaks_H3K27AC.pdf", "asset/2022/12_14_plt_top_p_peak_group_on_chr_H3K27AC.pdf"), error = FALSE)
```

- More detailed p-values for (a SNP, a peak group) for a few peak groups with significant p_acat. See more [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G56480.pdf), [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G57648.pdf), [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G57649.pdf).

```{r out.width="30%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_p_peak_group_H3K27AC_G57644.pdf"), error = FALSE)
```

### Observations

- Looks like p-values by ACAT are similar to p-values by minp adjusted by Bonferroni correction.

- The minimum p-values are ~1e-6.

- Why no significant associations?
  
  - I only test ~3k peak groups that have overlapped SNPs within 100kb window. So these peak groups are very close. So, combining these peaks don't have much improvement.
  
  - If I include more peak groups (and more SNPs) that are not so close for association test, by extending 100kb cis window to 1Mb cis window, maybe there can be more significant p-values.)
  
  - Will update the numbers after Carlos sends me the 1Mb cQTL associations.



# Dec 09

## Quick Summary

- Preliminary analysis on Carlos's hQTL results.


## Carlos's analysis and results

- A few questions
  
  - Sample size - H3K27AC (78/72), H3K4ME1 (77), H3K4ME3 (78), H3K36ME3 (95)
  
  - Why use genes as phenotype for H3K36ME3 but not peaks?
  
  - For mark H3K36ME3, peak names used for `Counts.txt`, but gene names used for the other files. A conversion file?
  
  - In file `NominalPass.txt.gz`, what's the nominal p-value cutoff?


- Data of H3K27AC, H3K4ME1, H3K4ME3, and H3K36ME3 chromatin marks
  
  - ChIP-seq data for H3K27AC, H3K4ME1 and H3K4ME3 chromatin marks in 75 LCLs from Yoruba invididuals was publicly available from a study by Grubert et al (2015). 
  
  - We produced in this study the Cut&Tag data for the H3K36ME3 chromatin mark in 96 LCLs from Yoruba individuals. 


- Pre-processing
  
  - We aligned the reads from all experiments to the GRCh38 human genome using HISAT. 
  
  - Peak calling for the ChIP-seq data was performed with MACS2 for H3K27AC and H3K4ME1 (narrow peaks), and for H3K4ME3 (broad peaks). 
  
  - For each individual, quantified ChIP-seq coverage for the three marks across the peaks using featureCounts. 
  
  - After filtering for low coverage and low variance, we were left with 100858 peaks for H3K27AC, 182749 peaks for H3K4ME1, and 55769 peaks for H3K4ME3. 
  
  - H3K36ME3 is a chromatin mark associated with transcription, and it doesn’t form clearly defined peaks like the other marks. For H3K36ME3, we quantified coverage across the top expressed 14000 protein coding genes with featureCounts. The set of top expressed genes was determined with mRNA expression in LCLs from Yoruba invidivuals in RNA-seq data from the Geuvadis consortium.


- Normalization
  
  Each phenotype (peaks or genes) by individuals coverage table was normalized as follows: 
  
  - first, for each individual we normalized the raw peak or gene counts to counts per million (CPM). 
  
  - Second, for each phenotype we applied the standard normalization across all individuals. 
  
  - Finally, for each individual we applied the rank-based inverse normal transformation across all phenotypes. 


- hQTL calling
  
  - hQTLs were called using QTLTools with permutation pass and nominal pass. We used a cis window of 100 kb, and the principal components as covariates.


- Results
  
  In summary, for each of H3K27AC, H3K4ME1 and H3K4ME3 we have a set of peaks. For each of the four chromatin marks (including H3K36ME3), we have the following data:
  
  - **Raw counts**: Phenotype (peaks or gene) by individual table of raw counts.
  
  - **Normalized counts**: Phenotype by individual table of qqnorm data (normalization described above)
  
  - **Permutation pass (top hQTL-peak/gene association)**: Table with top hQTLs for each phenotype from QTLTools in permutation pass.
  
  - **Nominal pass (all hQTL-peak/gene associations within 100kb windows of the peak)**: Table with hQTLs results for each SNP within 100kb of each phenotype from QTLTools in permutation pass.





## Strong tag enriched peaks

### Look at peaks

Questions of interest:

- Length of merged peaks

- Number of sub-peaks merged into large peaks

- Distance between peaks



### Look at pQTL effects

Questions of interest:

- What is the proportion of peaks with pQTLs?

  - For mark H3K27AC , there are 105049 peaks in total. After preprocessing, 100858 peaks are left for QTL calling. **7380 peaks ( 0.07317218 ) have significant pQTLs**, under FDR < 0.05 .
  
  - For mark H3K4ME1 , there are 190250 peaks in total. After preprocessing, 182749 peaks are left for QTL calling. **4383 peaks ( 0.02398372 ) have significant pQTLs**, under FDR < 0.05 .
  
  - For mark H3K4ME3 , there are 58171 peaks in total. After preprocessing, 55769 peaks are left for QTL calling. **3246 peaks ( 0.05820438 ) have significant pQTLs**, under FDR < 0.05 .


```{r out.width="30%", fig.cap="Significant peaks of mark H3K27AC.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/1209_dis_sig_peak_H3K27AC.pdf"), error = FALSE)
```


- Length of peaks with & w.o. pQTLs

```{r out.width="50%", fig.cap="Peak length of mark H3K27AC.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/1209_dis_peak_len_H3K27AC.pdf"), error = FALSE)
```


**- Reads count of peaks with & w.o. pQTLs**
**- Peak enrichment (weak v.s. strong) for peaks with & w.o. pQTLs**



- What is the distribution of effect sizes for peaks (with pQTL & without pQTLs)?
  
  - Distribution of all effects
  
  - Distribution of all effects on the dimension of SNPs and peaks coordinates
  
  - Distribution of the most significant effect for each peaks across SNPs


~~- Distribution of peaks with pQTL & without pQTLs?~~


- Are peaks without pQTLs more likely to be peaks with merged sub-peaks? (Can combining multiple sub-peaks in a large peak improve power than considering the large peak as a whole?)

**- Are peaks without pQTLs more adjacent than peaks with pQTLs? (Can combining multiple adjacent peaks improve power than using individual peaks?)**




## Weak tag enriched peaks


## What type of peaks should have improved QTL calling?

## How to improve?

1. Combine two peaks

2. Combine sub-peaks for one peak


