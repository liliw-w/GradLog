---
title: "Log2023"
output:
  workflowr::wflow_html:
              toc: true
              toc_depth: 4
editor_options:
  chunk_output_type: console
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, out.width = "50%")
```


```{css style settings, echo = FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 16px;
    border-left: 5px solid #eee;
}
```

**If any figures don't show, try opening in Safari.**

# Sep 06 & Sep 13

As shown in last week, to compre to Dutta et. al., I proposed three ways -

1. Direct comparison - compare eQTLGen results

2. Under our case - reduce archie multiple variants to one single variant
  
   Use our simulated data.

3. Under their case - ~~aggregate trans-pco single variants as a set~~
  
   Instead, run trans-pco on archie selected gene sets and all eQTLGen single variants.


I did way 1. This week I will do 2 and 3.



## 1. Trans-PCO on archie selected gene sets (Way 3)

### How?

- Estimate $\hat{\Sigma}_{nullZ}$ for each gene set
  
  A SNP has p > 1e-4 for all genes in the set, as a null SNP. Same threshold as used in paper. Use independent null SNPs to estimate $\hat{\Sigma}_{nullZ}$.

- Define trans variants
  
  Run for only trans variants. Same def of trans as used in archie paper. Either more 5Mb away from all genes or on a different chromosome.



### Results

- #independent null SNPs for estimating $\Sigma_{nullZ}$ v.s. gene set size

- p value distribution

```{r out.width="40%", fig.cap="Figure: #independent null SNPs for estimating Sigma_{nullZ} v.s. gene set size for archie signal sets. X-axis is archie significant gene sets. Y-axis is either gene set size (light blue) or number of independent null SNPs used for estimating Sigma for that set (dark blue).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_06_plt_gene_indepnull_size.pdf"), error = FALSE)
```


```{r out.width="40%", fig.cap="Figure: P value of archie gene sets by trans-pco. Each panel is a trait and a significant archie component (selected genes, selected snps). X-axis is snps, y-axis is -log10(P). Each point is a snp. (A) Archie gene set v.s. all eQTLGen SNPs (trans). Red cross are variants selected by archie corresponding to the gene set. (B) Draw archie variants only. Dash line is p cutoff 0.05.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_06_plt_archie_pco.pdf"), error = FALSE)
```



### Observations

- Some archie gene sets also have small p values for their corresponding selected variants by trans-pco (fig. B), e.g. gene sets of Schizophrenia_C1, Prosc_C1, UC_C1. Mostly first component.

- But some archie gene sets have large p values for their corresponding selected variants by trans-pco (fig. B), e.g. gene sets of Pros_C2, UC_C2. Mostly second component.

- Some archie gene sets have small p values for additional variants by trans-pco (fig. A).


### Updated results

For each trait, I adjusted pco p using bonferroni correction by multiplying nominal p by total number of test for each trait (~9918 * #components). FDR level 0.05. Figure below shows adjusted pco p values.

We observe that -

- For most archie signal components (except UC_C2), there is at least one archie-selected snp that are also significant by trans-pco.

- Similar observation as above, less variants from the second component (Prosc_C2, UC_C2) are replicated.


```{r out.width="40%", fig.cap="Figure: Adjusted P value of archie gene sets by trans-pco. Each panel is a trait and a significant archie component (selected genes, selected snps). X-axis is snps, y-axis is -log10(P). Each point is a snp. (A) Archie gene set v.s. all eQTLGen SNPs (trans). Red cross are variants selected by archie corresponding to the gene set. (B) Draw archie variants only. Dash line is p cutoff 0.05. (C) Number of archie selected variants of each component that are (dark) or not (light) trans-pco signals.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_13_plt_archie_pco.pdf"), error = FALSE)
```



## 2. Archie on our simulated data (Way 2)


### How?

Input of archie -

- $\Sigma_{GG}$
  
  Column-correlations of genetic variants.
  
- $\Sigma_{EE}$
  
  Column-correlations of gene expressions.

- $\Sigma_{GE}$
  
  Cross-covariance matrix between variants and gene expressions.


Our simulated data -

- Gene module of size 101, and one snp.

- In this case, $\Sigma_{GG}=1$, $\Sigma_{EE}=\Sigma$

- $\Sigma_{GE}$ is tricky **[Is it correct?]**
  
  According to archie paper, $(\Sigma_{GE})_{ij} = \frac{Z_{ij}}{\sqrt{2Nmaf_i(1-maf_i)}}$.
  
  We don't have $maf_i$. Instead, I used $(\Sigma_{GE})_{ij} = \frac{\beta}{\sigma_b}$.
  
  So, $(\Sigma_{GE})_{ij}$ only depends on $prop_caus$, $\sigma^2_b$.

- Simulation params **[Is it correct?]**
  
  I change various $\sigma^2_b$, generate $\beta \sim N(0, \sigma^2_b)$ for $\gamma$ SNPs, and $0$ otherwise, estimate $(\Sigma_{GE})$, run 1000 simulation, calculate 1000 cc value by archie.
  
  A bit different than trans-pco simulation, where I generated 10k z scores for each simulation.


### Results


```{r out.width="30%", fig.cap="Figure: Distribution of archie cc value of simulated data across various genetic variance. Box plot for 1000 simulations.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_06_plt_archie_cc_value.pdf"), error = FALSE)
```


### Observations

- All cc values are small. Power is low no matter what cc value cutoff is used.

- Not sure results are correct, mainly due to confusions on running archie code -
  
  - Is archie $(\Sigma_{GE})$ correct? Only depend on caus, var? not N?
  
  - Archie code bug in W?
    
    In archie paper, $W = \Sigma_{GG}^{-1/2} \Sigma_{GE} \Sigma_{EE}^{-1/2}$.
    
    However, in code `W <- Sigma_GG%*%Sigma_GE%*%Sigma_EE;`

- Were my previous simulations of trans-pco correct?
  
  For (gene set, a snp), I generated one $\beta \sim N(0, \sigma^2_b)$ for 10k snps in each simulation. In one simulation, 10k SNPs have z scores generated from same $\beta$ of $z \sim N_K(\sqrt{n} \beta, \Sigma_{K \times K})$. Across simulation, $\beta$ are different.



### ~~New equation to estimate $\Sigma_{GE}$~~

~~It should be $(\Sigma_{GE})_{ij} = \frac{\beta}{\sigma_b} \sqrt{N}$. So, $(\Sigma_{GE})_{ij}$ depends on $prop_caus$, $\sigma^2_b$, $N$.~~

I run 1000 simulation using this new equation. cc values of simulated data shown in figure below. Observations keep same -

- All cc values are small. Power is low no matter what cc value cutoff is used.

- cc values are even smaller (<1e-4) than above case.

```{r out.width="30%", fig.cap="Figure: Distribution of archie cc value of simulated data across various genetic variance. Box plot for 1000 simulations. Use new equation adding sqrt{N}.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_13_plt_archie_cc_value_addN.pdf"), error = FALSE)
```



### Cutoff of cc value

Previously, I thought ~0.07 cc value is low. But I checked ccvalues of signals in archie paper, turns out the cc values are also ~0.08.


- Cutoff used in archie paper

  Their cc value of significant signals are low as ~0.08 [figure in their paper](https://www.nature.com/articles/s41467-022-31845-9/figures/3).

  So we can't define significance simply based on a general sense of correlation.


- Solutions to define cutoff

  Use empirical null of cc values of null simulations

  I wanted to calculate p value of cc value of null simulations, as the way they used in the above figure, where they use competitive null distributions.
    
  Here is how they did it -

  > Then we use ARCHIE with the same sparsity levels as the original analysis, to extract the gene and variant components and calculate corresponding cc values. We repeat this step multiple (M) times to generate a competitive null distribution of cc values. We then evaluate the observed cc-values from the original analysis against the corresponding competitive null distributions to calculate the p-value.

  p-value = expected number of null cc-value larger than the observed cc-value (wrong equation (5) used in the paper). Then we will have P value distribution and calculate the power under $\alpha$.
 
  However, in our simulation setting where we simulated from $\beta$,  $(\Sigma_{GE})_{ij} = 0$, $W = 0$.



- Look at selection of SNPs & genes

  Another way to look at the performance of archie is to check if the selected genes by archie are real target genes (we have 30% genes out of 101 have non-zero effect). So I looked at the numebr of selected genes by archie on simulated alternative data.
  
  Archie selected more genes than real target genes.

```{r out.width="30%", fig.cap="Figure: Numebr of selected genes by archie on simulated alternative data across various genetic variance. Box plot for 1000 simulations. LEFT: old derivation. RIGHT: new derivation with sqrt{N}.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/09_13_plt_archie_selected_gene.pdf", "asset/2023/09_13_plt_archie_selected_gene_addN.pdf"), error = FALSE)
```




# Aug 16 & Aug 23

## 1. Change the way to define overlap of a window and a peak

### New way

<center>
![Define overlap of window and peak.](asset/2023/08_23_def_overlap_window_peak.jpg){width=40%}
</center>


- Original way
  
  In the original def, (1) a window overlap with a peak if this peak's center is within the window. (2) a peak overlap with a window if this peak's center is within the window.

- Issue
  
  However, there is issue with this def.
  
  When width_window > width_peak (mark H3K27ac), this def is okay.
  
  But when width_window < width_peak (mark H3K36me3), even when a window is included within a peak, the peak's center can still be outside the window.


- New way
  
  So the new way is, a window overlap with a peak OR a peak overlap with a window, no matter width_window > width_peak OR width_window < width_peak, if
  
  **Peak center within window OR window center within peak.**
  
  Using center ensures at least half of the shorter one (window or peak) is included in the other long one.


### Updated figures & observations

- New way works
  
  Look at case of overlapseg (Lower panel right purple).
  
  H3K36ME3. Changed. Indicates the new way works.
  
  H3K27ac. Stay same. Indicates both old and new way work, as window larger than peak size.
  
- Less new signals but still many
  
  Look at upper panel right purple.
  
  Less purple that are cwindows but not cpeaks.

- Less signals not overlap with any peak, but still many.
  
  Look at lower panel right purple.
  


1. H3K36ME3_window50kb_cis500kb_seg2kb

- peak_overlapseg
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlapseg_new.pdf){width=40%}
  ![Old](asset/2023/08_02_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlapseg.pdf){width=40%}


- peak_overlap
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlap_new.pdf){width=40%}
  ![Old](asset/2023/08_02_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlap.pdf){width=40%}


- prop_40
  
  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_40_new.pdf){width=40%}
  [Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_40.pdf){width=40%}

- prop_45
  
  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_45_new.pdf){width=40%}
  [Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_45.pdf){width=40%}

- prop_50

  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_50_new.pdf){width=40%}
  [Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_50.pdf){width=40%}


2. H3K36ME3_window50kb_cis500kb_seg5kb

- peak_overlapseg
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlapseg_new.pdf){width=40%}
  ![Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlapseg.pdf){width=40%}


- peak_overlap
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlap_new.pdf){width=40%}
  ![Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlap.pdf){width=40%}



3. H3K36ME3_window50kb_cis500kb_seg1kb

- peak_overlap
  
  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg1kb_peak_overlap_new.pdf){width=40%}
  [Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg1kb_peak_overlap.pdf){width=40%}



4. Previous figures on H3K27ac

- peak_overlapseg
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_peak_overlapseg_new.pdf){width=40%}
  ![Old](asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_peak_overlapseg.pdf){width=40%}


- peak_overlap
  
  ![New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_peak_overlap_allchr_new.pdf){width=40%}
  ![Old](asset/2023/07_19_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_peak_overlap_allchr.pdf){width=40%}


- prop_10
  
  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_10_new.pdf){width=40%}
  [Old](asset/2023/07_26_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_10.pdf){width=40%}

- prop_15
  
  [New](asset/2023/08_23_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_15_new.pdf){width=40%}
  [Old](asset/2023/07_26_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_15.pdf){width=40%}




## 2. Revision on paper 1 - Add simulations

**Goal - According to reviewer 3, to show multi is not always more powerful than uni test, at some cases.** -

## Reviewer's comment
  
1. at high level of sparsity
  
In current simulations with high sparsity, power of all methods is too low to be differentiated. So, to increase power at this setting to differentiate methods, I change to -
  
- increase effect sizes
  
  e.g. change sparsity level in Fig. S1
  
  [**This is equivalent to say to zoom in Fig. 2A, to make three tests differiatable from each other - increase power and pull them away from 0.**]

- ~~Or, use a larger sample size~~
    
  > "if you think increasing effect size in high sparsity setting is artificial"


~~2. low level of correlation among variates~~


[**I will do the case of "increase effect sizes".**]


## Simulation params
  
  $z \sim N_K(\sqrt{n} \beta, \Sigma_{K \times K})$, where $\beta \sim N(0, \sigma^2_b)$ for $\gamma$ SNPs, and $0$ otherwise.
  
  Params - $\Sigma_{K \times K}$, $n$, $\gamma$, $\sigma^2_b$.


## How? (High sparsity, large effect size)
  
  High sparsity in Fig. 2A ($\gamma = 1\%, 5\%, 10\%$), with larger genetic variance $\sigma^2_b = 0.005, 0.01, 0.05, 0.1, 0.2$.
  
  101 genes, N 500, 10k SNPs, 1k simulations, 5% fdr level.


- Calculate FDR & power
  
  Based on null empirical FDR ($10^7$ = null SNPs).
  
  #positive SNPs/#SNPs.


## Figures & Observations
  
  - With effect sizes being increased, pco and minp have larger power at high sparsity, thus can be well compared - power away from 0.
  
  - When 1% (1) gene is causal, minp is better.
  
  - When 5% or 10% genes are causal, pco is better.


```{r out.width="25%", fig.cap="Figure: Power plot across various genetic variances. x-axis shows causal proportion. y-axis shows power. Color for three methods.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_23_plt_power_lowCaus_highb_changecaus_varb0.005_N500_K101.pdf", "asset/2023/08_23_plt_power_lowCaus_highb_changecaus_varb0.01_N500_K101.pdf", "asset/2023/08_23_plt_power_lowCaus_highb_changecaus_varb0.05_N500_K101.pdf", "asset/2023/08_23_plt_power_lowCaus_highb_changecaus_varb0.1_N500_K101.pdf", "asset/2023/08_23_plt_power_lowCaus_highb_changecaus_varb0.2_N500_K101.pdf"), error = FALSE)
```



## 3. Revision on paper 1 - Compare to Dutta et. al.

### Their idea
  
- Goal
  
  Estimate correlation between gene sets associated to set of trait-related SNPs.
  
- Method
  
  Use sparse CCA.
  
- Result
  
  Selected genes associated with selected variants from sets.

- Data
  
  eQTLGen sum stats, LD matrix among variants, co-expression matrix among genes.

- Output
  
  cc value (association between the selected sets of variants and genes). Not p value. They use empirical p value by re-sampling random eQTLGen SNPs and genes.
  
  P value is for trait specific trans associations (not general associations).


### How to compare to?

- Why archie and trans-pco are not directly comparable?

  - Goals of ARCHIE ~~and the standard analysis~~ and our method are different and therefore not directly comparable.
  
  - ARCHIE identify gene sets associated to set of variants.
  
  - Output cc value (measure of association between the selected sets of variants and genes) not p value. empirical p value for trait specific associations.


[**But I come up with several ways for a general comparison -**]

1. Direct comparison - compare eQTLGen results

This is to compare **trait specific associations** under competitive null. To see if archie genes and variants were replicated in our analysis.

  - Compare gene component (selected genes)
    
    See if selected genes are replicated in trans target gene modules. ~~If same module (number of module distributed). If same variants.~~
    
  > The set of selected target genes in the gene component is one of the key outputs of ARCHIE.


  - Compare variant component (selected variants)
    
    See if selected variants are replicated in trans signals. ~~If same target module.~~
    
  - ~~Association patterns of (module, variants) including these components.~~


2. Under our case - reduce archie multiple variants to one single variant
    
This is to compare general associations under general null.

Run archie for each module we analyzed in eQTLGen and a SNP. Only use top component for significance. Try different cutoff on cc-value to claim significance and compare signals. Not to use their way of using empirical null p, computational expensive.


3. ~~Under their case - aggregate trans-pco single variants as a set~~



[**I will use the first way -**]



```{r out.width="40%", out.height="100%", fig.cap="Figure: Comparison with archie results. x-axis shows significant pairs of selected gene and variant set across three traits. 2/1/2 pairs for prostate cancer/schizophrenia/UC. y-axis shows the number of selected (A) genes and (B) variants. Lightest blue is the total number of selected (A) genes and (B) variants by archie. Middle blue is the number of these (A) genes and (B) variants included in our eQTLGen analysis. Dark blue is (A) genes one of our trans target modules, (B) variants that are also signals in our analysis. Red line shows the number of replicated signals whose target module also include their corresponding selected genes by archie.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_23_fig_compare_archie.pdf"), error = FALSE)
```


- Their results
  
  Pairs of (selected genes, selected variants of a trait) with significant correlations.
  
  Only results of three traits are available. They didn’t update results of all 29 traits they analyzed.
  
  2/1/2 pairs of (selected genes, selected variants of a trait) for prostate cancer/schizophrenia/UC.


- Our results

  DGN 166 co-expression modules and eQTLGen sum stats.
  
  > Of the 166 co-expression gene modules identified in DGN, we used 129 modules with reliable correlation matrix approximations to ensure the trans-eQTL signals are well-controlled for inflation.
  
  > We identified 8116 trans-eQTL SNP-gene coexpression module pairs, corresponding to 2161 eQTLGen test SNPs and 122 gene modules (Figure 5B, Table S11);


- Comparison & observations
  
  - Among selected genes by archie, all of those included in our eQTLGen analysis were in a trans target module (122). Could this because 122 modules out of 129 modules were all trans target module?
  
  - Among selected variants by archie, most were included in our analysis. But less than half were also trans signals.
  
  - And most of these trans signals are signals of the target module that include their corresponding selected genes by archie.



- Add a paragraph
  
  > Although ARCHIE also … identify gene sets associated to trait-related SNPs (regulated by sets of variants) by aggregating weaker trans associations, our method has different goals and are not directly comparable. Their primary objective is to capture trait specific trans-associations among gene and variant sets in the background of broad trans-associations that are expected to be seen in the genome, whereas our aim is to identify a comprehensive map of association in single-variant-module pairs irrespective of trait specificity. To compare generally …, we looked into if the selected genes/variants were replicated in trans target gene modules/trans signals (eQTLGen, supp notes, supp fig, supp table).



## 4. Zicheng's experience on scataq

- Observed Inflation
  
  Due to the error of not doing rank normal. Have been corrected.

- Caution on selecting window size for various cell types
  
  To keep peaks within window fewer than sample size, which can be small for some minor cell types after samples filtering. For these cell types, sample size small, window size should be small.
  
  Zicheng did whole blood, large cell type, no problem.

- Caution on normalization by rank normal peaks for minor cell types
  
  For minor cell types, peak read depth low, many peaks can have few reads. normalization points clustered at low reads. Should find out a way to remove or ...




# Aug 09

## 0. MultiCaQ-S for H3K27ac using QC peak_overlapseg {#H3K27ac-seg1b-peak-overlapseg}

- Goal
  
  To show **peak_overlapseg** for mark H3K27ac. Should be no much difference from previous **peak_overlap** results, as H3K27ac peaks are well defined.
  
  [`peak_overlapseg` means to retain only segs included by a peak.]
  
  [`peak_overlap` means to retain top X segs with high cpm. X is the number of segs included by any peak.]


- Signals
  
  Out of 26462 windows, 2994 are cwindows at FDR < 5%.
  
  [By comparison, peak_overlap: Out of 21290 windows, 2846 are cwindows at FDR < 5%.]

  
```{r out.width="25%", fig.cap="Figure: MultiCaQ-S for mark H3K27ac. QC filter on segments overlap with original peaks. (1) Comparison to univariate cPeaks. (2) Enrichment of eQTL in extra signals.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_peak_overlapseg.pdf", "asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K27AC_window50kb_cis500kb_seg1kb_peak_overlapseg.pdf"), error = FALSE)
```




## 1. Change segment size of MultiCaQ-S for H3K36me3 {#H3K36me3-seg1b-peak-overlap}

### Smaller seg size (1kb)

- Goal
  
  To show **seg1kb** results for mark H3K36me3. Compare to seg2kb.


- Signals

  seg1kb: Out of 44171 windows, 1028 are cwindows at FDR < 5%. 790 extra cwindows, 241 overlap with eQTLs.
  
  seg2kb: Out of 36688 windows, 1139 are cwindows at FDR < 5%. 892 extra cwindows, 279 overlap with eQTLs.


- Observations
  
  - Using 1kb seg has fewer cwindows than using 2kb seg.
  
  - Use even larger seg & window size?
  
  
```{r out.width="25%", fig.cap="Figure: MultiCaQ-S for mark H3K36me3. Using 1kb segs. (1) Comparison to univariate cPeaks. (2) Enrichment of eQTL in extra signals.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg1kb_peak_overlap.pdf", "asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg1kb_peak_overlap.pdf"), error = FALSE)
```


### Larger seg size (5kb)

- Why?
  
  Due to observations from [section](#H3K36me3-seg1b-peak-overlap) that using smaller seg size (1kb) has fewer cwindows than using 2kb seg.


- Goal
  
  Increase seg size to 5kb. 
  
  Proportion? Group size? Why not window size?


1. Segment group

```{r out.width="40%", fig.cap="Figure: Segment groups of H3K36me3_window50kb_seg5kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_seg_group_size_H3K36ME3_window50kb_seg5kb_peak_overlap.pdf", "asset/2023/08_09_seg_group_size_H3K36ME3_window50kb_seg5kb_peak_overlapseg.pdf"), error = FALSE)
```

- Similar pattern as the case of using 2kb seg. 
  
  Many groups include full segments (i.e. 10 = 50kb/5kb) for QC `peak_overlapseg`, as segments are adjacent to each other, while segments spans across groups for QC `peak_overlap`, as they were chosen as top segs.



2. cWindow

```{r}
knitr::kable(
    data.frame(
  'case' = c('Univariate', 'H3K36me3_window50kb_seg2kb_peak_overlap', 'H3K36me3_window50kb_seg2kb_peak_overlapseg', 'H3K36me3_window50kb_seg5kb_peak_overlap', 'H3K36me3_window50kb_seg5kb_peak_overlapseg'),
  'total window/peak' = c(14000, 36688, 24706, 28106, 24165),
  'cwindow/peak' = c(338, 1139, 636, 1355, 759)
),
    caption = "Out of *** windows/peaks, *** are cwindows/cpeaks at FDR < 5%."
  )
```



3. Signal comparison v.s. uni

```{r out.width="40%", fig.cap="Figure: Comparison to univariate cPeaks. H3K36me3_window50kb_seg5kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlap.pdf", "asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlapseg.pdf"), error = FALSE)
```


- More new cwindows found by using 5kb seg size than 2kb seg.

- Similar as case of 2kb seg, we should include more seg than just segs overlap with any peak.


4. Enrichment of eQTL in extra signals

```{r out.width="25%", fig.cap="Figure: Enrichment of eQTL in extra signals. H3K36me3_window50kb_seg5kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlap.pdf", "asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg5kb_peak_overlapseg.pdf"), error = FALSE)
```



## 2. MultiCaQ-S for H3K36me3 keeping larger proportion of segments

- Why?
  
  Due to observations from [previous section](#H3K36me3-seg2kb-peak-overlap) that including extra segments that do not overlap with peak can generate extra windows. Therefore, I wanted to include those segs by increasing the proportion of segs with high cpm.


- Goal
  
  To show results of including more segments that do not overlap with originally called peaks.


- How?
  
  - Use proportion of segs to keep segs with high cpm.
  
  - ~35% (486843/1378402) segments (2kb) overlap with a peak.
  
  - Larger proportions: 40%, 45%, 50%.


- Observations
  
  - In [previous section](#H3K27ac-seg1kb-qc) for mark H3K27ac, we showed including more segments that do not overlap with originally called peaks did not increase signals.



1. Segment group

```{r out.width="30%", fig.cap="Figure: Segment groups of H3K36me3_window50kb_seg2kb, using QC based on proportion of included segs. Groups including higher proportion of segs have larger group sieze.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_seg_group_size_H3K36ME3_window50kb_seg2kb_prop_40.pdf", "asset/2023/08_09_seg_group_size_H3K36ME3_window50kb_seg2kb_prop_45.pdf", "asset/2023/08_09_seg_group_size_H3K36ME3_window50kb_seg2kb_prop_50.pdf"), error = FALSE)
```


2. cWindow

```{r}
knitr::kable(
    data.frame(
  'case' = c('Univariate', 'H3K36me3_window50kb_seg2kb_peak_overlap', 'H3K36me3_window50kb_seg2kb_peak_overlapseg', 'H3K36me3_window50kb_seg5kb_peak_overlap', 'H3K36me3_window50kb_seg5kb_peak_overlapseg', 'H3K36me3_window50kb_seg2kb_prop_40', 'H3K36me3_window50kb_seg2kb_prop_45', 'H3K36me3_window50kb_seg2kb_prop_50'),
  'total window/peak' = c(14000, 36688, 24706, 28106, 24165, 40490, 43760, 46340),
  'cwindow/peak' = c(338, 1139, 636, 1355, 759, 1143, 1179, 1204)
),
    caption = "Out of *** windows/peaks, *** are cwindows/cpeaks at FDR < 5%."
  )
```



3. Signal comparison v.s. uni

```{r out.width="30%", fig.cap="Figure: Comparison to univariate cPeaks. H3K36me3_window50kb_seg2kb, using QC based on proportion of included segs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_40.pdf", "asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_45.pdf", "asset/2023/08_09_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_prop_50.pdf"), error = FALSE)
```


4. Enrichment of eQTL in extra signals

```{r out.width="30%", fig.cap="Figure: Enrichment of eQTL in extra signals. H3K36me3_window50kb_seg2kb, using QC based on proportion of included segs", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg2kb_prop_40.pdf", "asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg2kb_prop_45.pdf", "asset/2023/08_09_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg2kb_prop_50.pdf"), error = FALSE)
```



## 3. cwindows v.s. cpeaks

- Issue
  
  There are windows/cwindows not overlap with any peak, while all windows should consist of segs overlap with a peak.
  
  `count_based/nonoverlap_window/plot/plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlapseg.pdf`
  
  To see if a window overlap with any I used center of a pea
  
  All peak centers are in a window.
  
  
- Why this issue diappears for mark H3K27AC?
  
  See [section](#H3K27ac-seg1b-peak-overlapseg).


- Another way to check overlap





# July 19 & July 26

## 1. Whole-genome wide QC {#H3K27ac-seg1kb-qc}

### Three ways

- To make #segments ~ #peaks

- To retain segments overlap with any peak

- Use segment cpm proportion - 10%, 15%
  
  To retain seg overlap with any peak, the proportion is ~8%. Therefore, trying 10% and 15%.


### Ways comparison

Add the old way using chr-wise factor

- #segment

  QC_peak_number: 100845
  
  QC_peak_overlap: 210076
  
  QC_prop_10: 274161
  
  QC_prop_15: 411242


- quantile cutoff
  
  0.03678267
  
  0.07662449
  
  0.1
  
  0.15

- cpm cutoff
  
  0.4083591
  
  -0.860688
  
  -1.184399
  
  -1.547873

- Individual total reads
  
  Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
  
  10786452 14324385 15495376 15509431 16699293 19339800



### Signals

1. Segment group

```{r out.width="23%", fig.cap="Figure: Segment group size of QC to make segments number be the same as (1) peak number, (2) segments overlap with any peak, (3) top 10% segs, and (4) top 15% segs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_19_plt_seg_group_window50kb_avgcpmfct2_seg1kb_peak_number.pdf", "asset/2023/07_19_plt_seg_group_window50kb_avgcpmfct2_seg1k_peak_overlap.pdf", "asset/2023/07_26_plt_seg_group_H3K27AC_window50kb_seg1k_prop_10.pdf", "asset/2023/07_26_plt_seg_group_H3K27AC_window50kb_seg1k_prop_15.pdf"), error = FALSE)
```

Largest group has  segments. Most groups have <10 segments.


2. cWindow

Peak_number: Out of 14523 windows, 2398 are cwindows at FDR < 5%.

Peak_overlap: Out of 21290 windows, 2846 are cwindows at FDR < 5%.

QC_prop_10: Out of 23750, 2806 are cwindows at FDR < 5%.

QC_prop_15: Out of 27567, 2562 are cwindows at FDR < 5%.


3. Signal comparison v.s. uni

```{r out.width="23%", fig.cap="Figure: Comparison to univariate cPeaks. Use QC to make segments number be the same as (1) peak number, (2) segments overlap with any peak, (3) top 10% segs, and (4) top 15% segs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_19_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_peak_number_allchr.pdf", "asset/2023/07_19_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_peak_overlap_allchr.pdf", "asset/2023/07_26_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_10.pdf", "asset/2023/07_26_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_seg1kb_prop_15.pdf"), error = FALSE)
```


4. Extra cQTLs enrichment for eQTLs


```{r out.width="23%", fig.cap="Figure: Enrichment of eQTLs in extra cQTLs. Use QC to make segments number be the same as (1) peak number, (2) segments overlap with any peak, (3) top 10% segs, and (4) top 15% segs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_26_plt_enrich_extra_cqtl_eqtl_window50kb_avgcpmfct2_seg1kb_peak_number.pdf", "asset/2023/07_26_plt_enrich_extra_cqtl_eqtl_window50kb_avgcpmfct2_seg1kb_peak_overlap.pdf", "asset/2023/07_26_plt_enrich_extra_cqtl_eqtl_window50kb_seg1kb_prop_10.pdf", "asset/2023/07_26_plt_enrich_extra_cqtl_eqtl_window50kb_seg1kb_prop_15.pdf"), error = FALSE)
```




## 2. MultiCAQ-S on broad mark H3K36me3 {#H3K36me3-seg2kb-peak-overlap}

In total, 95 samples.


### Way to filter segments?

Goal -

- To avoid peak calling (using the above QC dependent on peak calling is fine)

- Inaccurate peak calling (QC shouldn't depend on peak calling)


There are two ways of seg filtering -

- `peak_overlap`
  
  Use the proportion of segments that overlap with any peak as the cpm cutoff to retain segments.
  
  Clarify - Previous results on mark H3K27ac used this QC.

- `peak_overlapseg`
  
  Retain the exact segments that overlap with any peak.


### Wrangle bam

- Problematic sample reads assignment of mark H3K27ac
  
  There is one sample which had non-zero unassigned reads due to ambuiguity on chr20, which was supposed to be zero. (All other chr's and samples were fine.)

```{r out.width="40%", fig.cap="Figure: Problematic sample reads assignment of mark H3K27ac.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_02_plt_count_unassigned_ambiguity_H3K27AC_seg1kb.pdf"), error = FALSE)
```


- Speed up featureCounts
  
  Previously feature counting was slow. I did below to speed up.
  
  - Remove `-p`
  
  - Add slurm flag `cpus-per-task` for multi-thread


- For this mark, no samples with Unassigned_Ambiguity reads (featureCounts summary)
  
```{r out.width="40%", fig.cap="Figure: FeatureCounts summary for mark H3K36me3. No Unassigned_Ambiguity reads. This is seg2kb. Same for seg1kb.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_02_plt_read_assignment_sum_H3K36ME3_seg2kb.pdf"), error = FALSE)
```


### Parameters and why?

```{r out.width="40%", fig.cap="Figure: Peak width of mark H3K36me3.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c('asset/2023/04_19_plt_peak_width_H3K36ME3.pdf'), error = FALSE)
```

Peak width distribution -

```
Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

341   12992   32431   70270   77592 2172910
```

I wanted the window size to be approx median peak width, so that a window can span a whole peak for at least half of the peaks.


- Segment size
  
  1kb. 2kb.

- Window size
  
  50kb.

- QC seg filter
  
  peak_overlap. peak_overlapseg.



### Signals

1. Segment group

```{r out.width="40%", fig.cap="Figure: Segment groups of H3K36me3_window50kb_seg2kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_02_seg_group_size_H3K36ME3_window50kb_seg2kb_peak_overlap.pdf", "asset/2023/08_02_seg_group_size_H3K36ME3_window50kb_seg2kb_peak_overlapseg.pdf"), error = FALSE)
```

- Window size smaller than peak size? Dynamic? Half windows have full 2kb-seg (25), i.e. half peaks split into multiple windows.

- We should include more seg than just segs overlap with any peak.
  
  Why? See results below, using peak_overlap QC generates extra cwindows that don't overlap with any peaks.
  
  This makes sense, as those called peaks were not accurate, some regions with high cpm were not included in the peaks.



2. cWindow

- Univariate
  
  Out of 14000 called peaks, 338 are cpeaks at FDR < 5%.


- H3K36me3_window50kb_seg2kb_peak_overlap
  
  Out of 36688 windows, 1139 are cwindows at FDR < 5%.


- H3K36me3_window50kb_seg2kb_peak_overlapseg
  
  Out of 24706 windows, 636 are cwindows at FDR < 5%.



3. Signal comparison v.s. uni

```{r out.width="40%", fig.cap="Figure: Comparison to univariate cPeaks. H3K36me3_window50kb_seg2kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_02_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlap.pdf", "asset/2023/08_02_plt_cpeak_cwindow_seg_group_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlapseg.pdf"), error = FALSE)
```


- Extra cwindows not overlap with any peak, using QC peak_overlap (left figure, B, upper right)
  
  This indicates peak calling is not good in broad mark. Many segments with high cpm not called as peaks, but they have cQTLs by multicaq-S.
  
  Compared to narrow peak H3K27ac. Look at same panel. There is no purple bar, which means all cwindow overlap with a peak, which means segments with high cpm overlap with at least one peak, they are included by peak calling, i.e. peak calling was good.


- Some extra signals overlap with a peak but not a cpeak.


- As mentioned above, we should include more seg than just segs overlap with any peak.
  
  Why? Using peak_overlap QC generates extra cwindows that don't overlap with any peaks.
  
  This makes sense, as those called peaks were not accurate, some regions with high cpm were not included in the peaks.
  
  Including these extra segments generates extra signals.



4. Enrichment of eQTL in extra signals

```{r out.width="40%", fig.cap="Figure: Enrichment of eQTL in extra signals. H3K36me3_window50kb_seg2kb, using QC peak_overlap (left) and peak_overlapseg (right).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/08_02_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlap.pdf", "asset/2023/08_02_plt_enrich_extra_cqtl_eqtl_H3K36ME3_window50kb_cis500kb_seg2kb_peak_overlapseg.pdf"), error = FALSE)
```



# July 12

## 1. MultiCAQ-S on mark H3K27ac

### Parameters

- Mark: H3K27ac

- Segment size: 1kb

- Window size: 50kb

- Nonoverlap window

- QC AVE_CPM_FCT: 2

  To filter low abundance segments. Factor multiplying median(ave_logcpm). CPM is chr-wise, i.e. sum reads of an individual on a chr. [From the results, should try genome-wise QC.]


### Signals itself

1. Segments and QC

To filter segments, I calculate median(ave_logcpm) for each chr, and retain segments with logcpm > 2*median(ave_logcpm).

```{r out.width="40%", fig.cap="Figure: QC on segments. (A) median(ave_logcpm) used for filtering segments across chr. (B) Total number of segments across chr. (C) Distribution of ave_logcpm for segments across chr. Leftmost density is for genome-wide segments. (D) Number of retained segments after QC.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_12_plt_seg1kb.pdf"), error = FALSE)
```

(A) Chr-wise cutoff of median(ave_logcpm) is all positive. Positive median(ave_logcpm) cutoff multiplying a factor elevates cutoff with less segments left.

With (B), shorter chr has less sum reads, thus larger cpm, larger median(ave_logcpm) cutoff.

(C) Genome-wide has negative median(ave_logcpm). Multiplying it by a factor lowers cutoff with more segments left. It doesn't work to filter low abundance segments. Should think about another way to filter segments by genome-wide QC.


- chr-wise QC
  
  cpm < 0: c_i/sum_i(chr) < 1/10^6

- genome-wide QC - median(cpm) < 0
  
  cpm < 0: c_i/sum_i(all_chr) < 1/10^6


2. Segment group

```{r out.width="40%", fig.cap="Figure: Segment groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_12_seg_group_size_window50kb_avgcpmfct2_seg1kb.pdf"), error = FALSE)
```

Largest group has 50 segments. Most groups have <10 segments.


3. cWindow

Out of 17921 windows, 2499 are cwindows at FDR < 5%.

```{r out.width="40%", fig.cap="Figure: cWindows.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_12_plt_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_allchr.pdf"), error = FALSE)
```


### Signal comparison

1. v.s. uni

```{r out.width="40%", fig.cap="Figure: Comparison to univariate cPeaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_12_plt_cpeak_cwindow_seg_group_H3K27AC_window50kb_cis500kb_avgcpmfct2_seg1kb_allchr.pdf"), error = FALSE)
```

MultiCAQ-S found new signals than QTLTools. But less than MultiCAQ-P, see previous figure.

Try genome-wide QC? Chr-wise QC filtered too many segments on shorter chr's, where cutoff is high.


- with eQTLs

```{r out.width="40%", fig.cap="Figure: Enrichment of eQTLs in new cwindows.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/07_12_plt_enrich_extra_cqtl_eqtl_window50kb_avgcpmfct2_seg1kb.pdf"), error = FALSE)
```

Those new cwindows are enriched for eQTLs.


- with GWAS


2. v.s. MultiCaQ-P

At same window size 50kb, MultiCAQ-P found 7259 cwindows at FDR < 5%, out of 20648 windows.





# May 31 & Jun 07

## 1. coloc cQTLs with GWAS

### Starting from cQTL loci

- How?

  - With 29 blood trait GWAS from Neale's lab.
  
  - For each window, define 1Mb (500kb as cis) as coloc region, take overlapped snps with GWAS.

- Numbers


### Starting from GWAS loci - Neale lab

- How?

  - Define GWAS loci - Start with the smallest p, define a 1Mb (500kb as cis) flanking region as coloc region, search any remained snps with p < 1e-7. 
  
  - For each loci, take overlapped snps with any window.

  - PP4 > 0.75


- Numbers
  
  - Each trait has ~400 loci, ~20 are colocalized with cQTLs.

```{r out.width="40%", fig.cap="Figure: GWAS loci coloc with cQTLs. 29 blood traits.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/06_07_coloc_gwas_qtl.png"), error = FALSE)
```


- Low coloc number - possible reasons
  
  - Use maf for coloc. I used to use af that can be > 0.5.
  
  - Use 36 blood trait GWAS from Astle et al 2016 Cell that Ben used. Neale lab GWAS sum stats have some weird snps, e.g. af=1.
  
  - Region too wide? 500kb total.


### Use 36 blood traits - Ben used

- Ben's coloc results as comparison
  
  - Sample size smaller
  
  - Most of trait have between 100-300 gwas loci for coloc (though a lot of the loci are overlapping between the different gwas)
  
  - Overall, colocalize 329 gwas loci (not necessarily unique loci) to 183 distinct H3K27Ac peaks (not necessarily 1 peak per loci, could be more than one).


- How?

  - Define GWAS loci - Start with the smallest p, define a 1Mb (500kb as cis) flanking region as coloc region, search any remained snps with p < 1e-7. 
  
  - For each loci, take overlapped snps with any window.
  
  - Remove MHC region (chromosome 6: 25.9–33.4 Mb, genome build GRCh37).
  
  - PP4 > 0.5


- Numbers

  - Summary of gwas loci and coloc loci.
    
    Each trait has ~200 loci, ~10 (5%) are colocalized with cQTLs.
  
  - How many coloc gwas loci are extra new cQTLs (than univariate)?
    
    Most traits have only 1 coloc loci coloc with new cQTLs. 
  
  - How many coloc gwas loci are not eQTLs?
    
    Most traits have 5 coloc loci not overlap with any eQTL.


```{r out.width="40%", fig.cap="Figure: Summary of gwas loci and coloc loci. 36 blood traits. (A) x-axis: trait. Grey bar: GWAS loci. Red bar: coloc loci. (B) Number of coloc loci across traits. (C) Coloc proportion across traits.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/06_07_coloc_num.pdf"), error = FALSE)
```

```{r out.width="40%", fig.cap="Figure: Coloc loci compare with (A) if coloc loci coloc with new cQTLs compared to univariate. (B) if coloc loci overlap with any eQTL.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/06_07_coloc_compare.pdf"), error = FALSE)
```


## 2. Other two marks

### Enrichment




# May 19 & May 24

## 1. Peak-based all chromosome

- Top p for each window, correction on cis SNPs by ACAT

- Q-value fdr across windows genome-wide

- Univariate - QTLTools permutation p & fdr q-value for each peak


**Check window & peak overlaps**

```{r out.width="30%", fig.cap="Figure: Overlaps between cwindow and cpeak. 10kb & 50kb & 100kb window.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/05_19_plt_cpeak_cwindow_H3K27AC_window10kb_cis500kb_allchr.pdf", "asset/2023/05_19_plt_cpeak_cwindow_H3K27AC_window50kb_cis500kb_allchr.pdf", "asset/2023/05_19_plt_cpeak_cwindow_H3K27AC_window100kb_cis500kb_allchr.pdf"), error = FALSE)
```


## 2. The enrichment of eQTLs in extra identified cwindows/cQTLs

### How?

- Use cwindows from results of 50kb window.

- Find those extra cwindows (top cQTL) that don't overlap with any cpeaks by univariate mapping.

- Find those extra top cQTLs that overlap with eQTLGen eQTLs.
  
  - By overlap, I mean (1) simple overlap. (2) in LD (R2<0.8).
  
  - By eQTLGen eQTLs, I mean (1) all eQTLs. (2) top eQTL for each gene.


- Quanfify the enrichment of eQTLs in cQTLs
  
  - I finally used top cQTLs with simple overlap with all eQTLs.
    
    The reason is, if the top cQTL is not the lead eQTL, but secondary eQTL, we can still capture that kind of overlap. In addition, this way equals to using LD with top eQTL, because if a top cQTL is in LD with top eQTL, then this cQTL should also be an eQTL.


- Other details
  
  - I define matched SNPs between chip-seq and eqtlgen snps by lift over chip-seq to hg19. All successfully converted snps are considered to be matched SNPs in eqtlgen.
  
  - To quantify enrichment in those extra cQTLs, I used two sets of SNPs that belong to (1) matched SNPs & cQTLs & extra cQTLs. (2) matched SNPs & non-cQTLs (excluding those cQTLs).
  
  - One-side fisher exact test.


### Enrichment figure with number and pvalue labelled

The extra cQTLs are enriched for eQTLs. P-value is 1.8e-12. OR is 1.37.

```{r out.width="40%", fig.cap="Figure: The extra cQTLs are enriched for eQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/05_24_plt_enrich_extra_cqtl_eqtl_window50kb.pdf"), error = FALSE)
```


### Results for general cwindows

I was also curious to see the enrichment in all cQTLs. The enrichment for eQTLs is even more significant. P-value is 1.1e-122. OR is 2.24.

```{r out.width="40%", fig.cap="Figure: All identified cQTLs are enriched for eQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/05_24_plt_enrich_all_cqtl_eqtl_window50kb.pdf"), error = FALSE)
```




# May 03

## 1. Compare cwindow and cpeak overlaps

- For window-based, get adjusted p of a window by taking the best hit of the window and multiple by the number of cis SNPs (Bonferroni correction). Then do q-value to get adjusted p across windows. Compare with FDR level 5% to get significant cwindow. (Same FDR procedure as cpeaks of Ben & Carlos results.)


- Plot overlaps between cwindow and cpeak - four types of set replication

```{r out.width="40%", fig.cap="Figure: Overlaps between cwindow and cpeak.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/05_03_plt_cpeak_cwindow_H3K27AC_window10kb_cis500kb_chr20_avgcpmfct2_seg1kb.pdf"), error = FALSE)
```


- genometrack of cwindows do not overlap with cpeaks
  
  Check `/scratch/midway3/liliw1/chromatin/test_results`
  
- genometrack of cpeaks do not overlap with cwindows
  
  Check `/scratch/midway3/liliw1/chromatin/test_results`


## 2. Add peak-based

- The figure

- Compare to the seg-based above

- genometrack plot


## 3. Change top p correction from using Bonferroni to ACAT

- The figures

- Compare to the seg-based & peak-based above



# Apr 26

## 1. Show top p of seg-based and peak-based

Add this figure to previous section [Try other CPM cutoff factors](#try-other-cpm-cutoff-factors).

- Top p's are bonferroni corrected by multiplying the number of cis SNPs of a group. 

- Only show groups with top p < 1e-3.


## 2. More figures of comparison between multi-segments-PCO and uni-merged-segments


### Compare nominal top p-values by multi-segments-PCO and uni-merged-segments

Add this figure to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).

Use **nominal top p**, w.o. bonferroni correction by multiplifying number of cis SNPs of groups. We wanted to look at this because we think cis regions should have same #independent SNPs. Not much difference with top p with bonferroni correction.


### Only show groups with large top p difference

i.e. log(topp_diff)>2.

Add this figure to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).


### What are these groups?

Add figures to previous section [Compare top p-values by multi-segments-PCO and uni-merged-segments](#top-p-comparsion-multi-merged).


- Group size of seg/merged groups off diagonal line

- #Vars in cis of seg/merged groups off diagonal line




# Apr 19

## Quick summary

- Check peak width for marks

- Compare p-values by multi-segments-PCO and uni-merged-segments in terms of top p, small p, and all p.

- Not finish comparison in terms of cmerged_seg/csegment/cpeak-group. With questions.



## 1. Check peak width for marks

### Why?

To see what segment size should be used to cover a whole peak for different marks.


### Results

```{r out.width="40%", fig.cap="Figure: Peak width of marks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_plt_peak_width_H3K27AC.pdf", 'asset/2023/04_19_plt_peak_width_H3K4ME1.pdf', 'asset/2023/04_19_plt_peak_width_H3K4ME3.pdf', 'asset/2023/04_19_plt_peak_width_H3K36ME3.pdf'), error = FALSE)
```


### Observations

- For mark H3K27AC, the average peak width is ~1kb.

- Mark H3K36ME3 has very wide peaks.


## 2. Compare p-values by multi-segments-PCO and uni-merged-segments

### Look top p at all scenarios - seg size and cpm cutoff factor {#top-p-comparsion-multi-merged}

Last week, I compared top p for one scenario. See below for all scenarios across seg sizes and cpm cutoff factors.

```{r out.width="30%", fig.cap="Figure: Compare p of seg_multi_pco and seg_merged_uni in terms of top p of groups. Top p's are bonferroni corrected by multiplying the number of cis SNPs of a group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_1_plt_topp_multi_sum_chr20_avgcpmfct2_seg1.5kb.pdf", 'asset/2023/04_19_2_plt_topp_multi_sum_chr20_avgcpmfct2_seg2kb.pdf', 'asset/2023/04_19_3_plt_topp_multi_sum_chr20_avgcpmfct3_seg0.5kb.pdf', 'asset/2023/04_19_4_plt_topp_multi_sum_chr20_avgcpmfct3_seg1kb.pdf', 'asset/2023/04_19_5_plt_topp_multi_sum_chr20_avgcpmfct3_seg1.5kb.pdf', 'asset/2023/04_19_6_plt_topp_multi_sum_chr20_avgcpmfct3_seg2kb.pdf'), error = FALSE)
```


We also wanted to look at -

[Use nominal top p, w.o. bonferroni correction by multiplifying number of cis SNPs of groups. We wanted to look at this because we think cis regions should have same #independent SNPs. Not much difference with top p with bonferroni correction.](asset/2023/04_26_plt_topp_nominal_multi_sum_chr20.pdf)



Look into those seg/merged groups off diagonal line -

- [Only show groups with large top p difference, i.e. log(topp_diff)>2.](asset/2023/04_26_plt_topp_bigdiff_multi_sum_chr20.pdf)

- [Group size of seg/merged groups off diagonal line](asset/2023/04_26_plt_topp_bigdiff_group_size_multi_sum_chr20.pdf)

- [#Vars in cis of seg/merged groups off diagonal line](asset/2023/04_26_plt_topp_bigdiff_cissnp_multi_sum_chr20.pdf)




**Observations -**

- In terms of top p (with bonferroni correction on cis snps), seg_multi and seg_merged don't have much difference.



### Look all p from (SNP, group), not only just top p

No bonferroni correction just nominal p.

```{r out.width="30%", fig.cap="Figure: Compare p of seg_multi_pco and seg_merged_uni in terms of small p and all p of (SNP, seg group/merged group) pairs. Small p's show p < 1e-5. All p's show truncated QQ plot.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_19_1_plt_allp_multi_sum_chr20_avgcpmfct2_seg1.5kb.pdf", 'asset/2023/04_19_2_plt_allp_multi_sum_chr20_avgcpmfct2_seg2kb.pdf', 'asset/2023/04_19_3_plt_allp_multi_sum_chr20_avgcpmfct3_seg0.5kb.pdf', 'asset/2023/04_19_4_plt_allp_multi_sum_chr20_avgcpmfct3_seg1kb.pdf', 'asset/2023/04_19_5_plt_allp_multi_sum_chr20_avgcpmfct3_seg1.5kb.pdf', 'asset/2023/04_19_6_plt_allp_multi_sum_chr20_avgcpmfct3_seg2kb.pdf'), error = FALSE)
```

**Observations -**

- In terms of all p (without multiple testing correction), seg_multi is better than seg_merged only in case avgcpmfct3_seg2kb.



### Compare group in terms of csegment_group?

> Use the way how people find cpeak to find csegment_group. With multiple testing correction.

**Question -**

- Isn't this the same as [what I did](#top-p-comparsion-multi-merged) where I looked at top p (with bonferroni correction on cis snps)?

- Since last time we said what people want is csegment/cpeak_group, and given seg_multi and seg_merged are similar in terms of top p, should this be concerning?


## 3. Compare seg-based and peak-based in terms of csegment/cpeak_group

**Question -**

Same reason as above.




# Apr 05 & Apr 12

## Quick summary

- Updated figures and observations from last time, adding factor 1 and peak-based.

- Re-do segment-based by changing peak filtering from using average log2 CPM as cutoff to using average CPM.

- Tried using different segment sizes.

- Compared p-values of segment-multi PCO with segment-uni (merged reads from multiple segments).



## 1. Re-do peak filtering using average CPM, not log2 based

**Two changes on segment filtering based on cpm -**

1. Cutoff to be ave cpm, instead of ave log2 cpm as used in last time.

2. Use median across segments instead of mean, as large variation expected across segments. [Use mean of one seg across individuals, as similar count expected for individuals.]


- Should be adding the factor instead of multiplying. More stringent cutoff and less segments.


- Under CPM filtering cutoff, check segment numbers

```{r out.width="50%", fig.cap="Figure: How many segments are retained after removing segments based on average log2 CPM?", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_avgcpmfct.pdf"), error = FALSE)
```

- Under CPM filtering cutoff, check group size

```{r out.width="50%", fig.cap="Figure: Segment group size across various factors of average log2 CPM.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_group_size_avgcpmfct.pdf"), error = FALSE)
```


- Run all thing - Check p

```{r out.width="50%", fig.cap="Figure: P value distribution under various factors of log2 average CPM. Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_avgcpmfct.pdf"), error = FALSE)
```


```{r out.width="50%", fig.cap="Figure: QQ-plot of P values under various factors of log2 average CPM. I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_avgcpmfct_qqplot.pdf"), error = FALSE)
```


**Observation**

- I tried using mean of ave cpm as cutoff, too many segs were removed.

- More segments left.

- Use 2 or 3 to be comparable or better than peak based.

- Computation time on chr20: using 2 takes ~2h, 3 takes ~1h.

- P values under these factors not differ much, not as results from last time, because the number of tests do not differ much ...

- **Again, peak-based is the best in terms of QQ-plot, due to much less number of tests. Increase segment size?**



### csaw paper on filtering windows

- Check csaw's user guide for the histogram of CPM with their cutoff and background cutoff. They retain very few windows. (Page 25)


- Cutoff depends on mark binding site. Narrow v.s. Broad.

> Smaller minimum fold changes are recommended for diffuse marks where the difference from background is less obvious.




## 2. Use different segment sizes

### How?

Use 0.5kb, 1kb, 1.5kb, 2kb to define segment size.

Use factor 3 for all segment sizes.


### Results

- Check segment cpm distribution and numbers based on CPM filtering

```{r fig.cap="Figure: Use 0.5kb, 1kb, 1.5kb, 2kb to define segment size. With that, split chr20 into segments, and then apply cpm filtering using factor 3. (A) Log2(average cpm) distribution across segments under various segment sizes. (B) The number of retained segments after filtering segments based on (median of average cpm) times various factors.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_segsize.pdf"), error = FALSE)
```


- Check size of segment groups

```{r out.width="50%", fig.cap="Figure: Segment group size across various segment sizes after filtering segments using 3*median(average CPM).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_plt_seg_group_size_segsize.pdf"), error = FALSE)
```


- Check p

```{r fig.cap="Figure: P value distribution under various segment sizes after filtering segments using 3*median(average CPM). Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_segsize.pdf"), error = FALSE)
```


```{r fig.cap="Figure: QQ-plot of P values under various segment sizes after filtering segments using 3*median(average CPM). I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_05_compare_p_segsize_qqplot.pdf"), error = FALSE)
```



### Try other CPM cutoff factors {#try-other-cpm-cutoff-factors}

- Why? Use various cpm cutoff for various segment sizes. Larger segments, more reads, higher CPM, higher average CPM. If using the same cpm cutoff factor as smaller segments, the cutoff can be much higher and more segments would be filtered out.


- Check size of segment groups

```{r out.width="50%", fig.cap="Figure: Segment group size across various segment sizes after filtering segments using various CPM factor cutoffes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_plt_seg_group_size_avgcpmfct_segsize.pdf"), error = FALSE)
```


- Check p

```{r fig.cap="Figure: P value distribution under various segment sizes after filtering segments using 3*median(average CPM). Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_p_avgcpmfct_segsize.pdf"), error = FALSE)
```


```{r fig.cap="Figure: QQ-plot of P values under various segment sizes after filtering segments using 3*median(average CPM). I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_p_avgcpmfct_segsize_qqplot.pdf"), error = FALSE)
```



```{r fig.cap="Figure: Top P value distribution. Top p's are bonferroni corrected by multiplying the number of cis SNPs of groups. Only show groups with top p < 1e-3.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_26_compare_topp_avgcpmfct_segsize.pdf"), error = FALSE)
```



- **Observations**

  - Segment size still smaller than peak width.
  
  - **Again, peak-based is the best in terms of QQ-plot, due to much less number of tests. Increase segment size?**




- Solve questions written on the paper sheet - on read counting & cpm cutoff for various segment size.


- Check if -p -reduce read1.bam` has same alignment as` -p -reduce -O`


- Read counting is problematic.
  
  - seg1kb, different assigned reads for two run
  
  - `count_based/seg_chr/seg1kb_chr20.saf`
  
  - `count_based/featurecounts/3_Counts_paired_leftmost_onlyread1.txt` v.s `count_based/featurecounts/Counts_paired_leftmost_onlyread1_seg1kb_chr20.txt`


-   Try size options, large or small, for current narrow peaks or future wide peaks. Check segment numbers, group size.




## 3. Merge reads across segments

See some intuitions from [reading below](#sum_reads_across_seg).


### How?

- Filter segments first.

- The total read counts across segs in a window.

- Same QC and normalizations.

- cis - 500kb. Probably more test than PCO.

2266 groups.


### Comparison

- Top p

- #cis SNPs tested for each group


```{r fig.cap="Figure: (A) Comparion of top p of each group for segment_multi and segment_sum. Top p was bonferroni corrected by the number of cis SNPs tested for the group. (B) Distribution of number of cis SNPs tested for each group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/04_12_compare_multi_sum.pdf"), error = FALSE)
```



## 4. Ideas from reading

### Sum of reads for a peak v.s. slice the peak by windows/segments [@lun2016] {#sum_reads_across_seg}

If a region/peak is broad/diffuse, QTL effects on all parts of the peak are weak but consistent. Then summing of reads provides greater detection power for such regions, as large peaks can collect more read counts than small windows. And since each subinterval of the region has the same/positively correlated QTL effects, no benefit is gained from considering each subinterval separately with small windows.


### When is window-based strategy powerful - some intuitions

- When detecting complex DB events, use windowing to increase spatial resolution missed by peak calling -

> csaw was more powerful than other methods at detecting complex DB events, especially those involving changes in the width of a binding event.

> The relatively poor performance of peak-based methods can be attributed to the fact that each binding site is defined as a single peak by MACS or HOMER. 

> csaw is able to tile small windows across the binding site. Each window corresponds a different subinterval of the binding site, such that the magnitude of any changes in part of the site can be faithfully captured by a window.

In my case, also add a case of where intensity difference is low.

**This is actually different than our case, where we wanted the window size to be approximately peak size, so that a window group would contain multiple peaks to be jointly tested. However, the idea of csaw is to split a general complex peak to sub-intervals, each of which are captured by windows for increased resolution.**

- When the peak is narrow and easily identified, window-based strategy should have comparable power to peak calling.

> sharp peaks were easily identified by the peak calling software. In this case, windowing did not provide any useful gain in spatial resolution. Nevertheless, csaw still returned the same performance curve as the best peak-based methods.

**In our case, our idea should be more powerful than peak calling even when the peaks are well-defined, since we test multiple peaks jointly.**



## Choose ways to cluster windows/segments into groups





# Mar 29

## Quick summary

- Re-do segment-based by adding cpm filtering on segments.


## 1. Re-thinking of segment-based idea

### Segment-based for narrow peaks

-   Goal: to skip peak calling

-   Illustration figure - ideal case

    We want segment size to be peak-width to include multiple peaks together.

### Segment-based for braod peaks

-   Goal: to compensate peak calling

-   Illustration figure - ideal case

    We want segment size to be smaller than peak-width to split a broad peak to multiple segments.



## 2. Add cpm filtering on segments and re-do segment-based

### How?
  
  Average log2 CPM for each segment across samples. Mean of average log2 CPM. Add a factor.


### Under CPM filtering cutoff, check segment numbers

```{r out.width="50%", fig.cap="Figure: How many segments are retained after removing segments based on average log2 CPM?", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_plt_seg_avgcpmfct.pdf"), error = FALSE)
```

### Under CPM filtering cutoff, check group size

```{r out.width="50%", fig.cap="Figure: Segment group size across various factors of average log2 CPM.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_plt_seg_group_size_avgcpmfct.pdf"), error = FALSE)
```


### Run all thing

```{r out.width="50%", fig.cap="Figure: P value distribution under various factors of average log2 CPM. Only show small P < 1e-5. Lower panel shows the total number of tests under each scenario.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_compare_p_avgcpmfct.pdf"), error = FALSE)
```

See histogram for peak-based and factor 2 and 3 [here](asset/2023/03_29_compare_p_avgcpmfct_sub.pdf).


```{r out.width="50%", fig.cap="Figure: QQ-plot of P values under various factors of average log2 CPM. I sorted all P values but here I only show P < 1e-7", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_29_compare_p_avgcpmfct_qqplot.pdf"), error = FALSE)
```


**Observation**

- Use factor 3, in terms of,
  
  - Absolute number of small p values. Compare to factor 4 and 2.
  
  - Density of small p values. Compare to factor 4 and 2.
  
  - Computation speed.


**Updated Observation**

- Add segment-based using factor 1 and peak-based.

- Peak-based is comparable to segment-based using factor 2 and 3, in terms of absolute number of small p values.

- **But Peak-based is the best in terms of qq plot of all p values.**
  
  - This is due to though peak-based is comparable to segment-based using factor 2 and 3, it has much fewer tests.
  
  - Increase segment size?



### Issues

I can't do the following to-do as mentioned last time,

- cdf and histogram of all pvalues
  
  Looks exactly same and highly overlapped under various factors of average log2 CPM. Because most p values are large, so those small p values are only a few and their differences don't matter much when plotting all p values.

- scatter plot
  
  Impossible to plot all p values on a scatter plot. Instead, I plotted the QQ plot of all pvalues. Not sure if it is equal.



## 3. Ideas from reading

### 1kb is not wide as segment size for broad peaks

-   From literature, they typically use 1kb as bin size for broad peaks.

-   We don't need higher resolution for wide domain/peak so we actually want the segment to be wide.

-   If we apply this idea to narrow peaks - cut the peak to segments instead of joint multiple peaks, we need narrower segment.

### Why avoid peak calling? [@lun2016]

-   It can be problematic even for narrow peaks.

> To avoid the biases and loss of resolution associated with peak calling, the software packages USeq ([13](javascript:;)), diffReps ([14](javascript:;)) and PePr ([15](javascript:;)) have implemented windowing strategies.

-   Peak calling followed by other analysis, e.g. DB, can loss error control. So use a sliding window (de novo detection) instead.

    -   Window-based strategy has well controlled error rates - unlike peaks (peak calling and DB on the same dataset), windows are defined independently from the data.

-   In my case, add - peak calling for broad peaks

-   In my case, add - no need to learn peak calling



# Mar 08 & March 15 & March 22

## Quick summary

- Figured out Ben & Carlos's steps on their histone peak QTLs we used previously.

- Finish count-based / segment-based version of PCO.


## 1. What they did to process data for peak QTLs

To work on count based QTL mapping, I need to first figure out the exact steps Ben & Carlos's did to process the histone data and peak QTL mapping, in order to make consistent window-based and count-based QTL mapping. Below is a mindmap of steps, QC, normalization etc. of Ben & Carlos did to generate peak QTLs.

```{r out.width="100%", fig.cap="Figure: What Ben & Carlos did to process data.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_Histone_mark_reads.pdf"), error = FALSE)
```


## 2. Count based - Processing data

- Why?

- How? A few things to be changed
  
  Make pre-processing data consistent with window-based, except -
  
  - Redefine segments on genome as .saf rather than peak calling regions.
  
  - Adaptations to QC
    
    - Remove segments without any reads
    
    - Remove segments without reads in 1-?% individuals (I tried 100%, 50%)


### Split chr's by segments

- How?
  
  Split the chromosome from 0 to chromosome length by a segment size - 1kb.

- Number of segments across chr

```{r out.width="50%", fig.cap="Figure: Number of split segments compared to the called peaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_num_features.pdf"), error = FALSE)
```


### Count reads within each seg

- 4 histone marks (by ChIP-seq or CutAndTag) are all paired-end reads.


- Count by paired-end
  
  ~~No `-p`. Reads instead of paired-end fragments will be counted.~~
  
  Use `-p`. [Count fragment instead](https://support.bioconductor.org/p/67534/).


- Ways to count a read overlapped with multiple features
  
  [At first, I didn't think through this until I observed many unassigned reads due to Unassigned_Ambiguity.]
  
  - ~~Use `-p -O` to assign the read (1) to all overlapped features.~~ [FEATURECOUNTS PAPER SUGGESTION ON USING _O]

  - ~~Use `-p --largestOverlap` to assign the read (1) to the feature that has the largest number of overlapping bases.~~
  
  - ~~Use `-p --fraction -O` to assign a fractional count (1/y, where y is the total number of features overlapping with the read) to all overlapped features.~~
  
  - Use `-p --read2pos 5`. Think a fragment as a whole, and take the left-most base.
  
  - ~~Use `--read2pos 5` to reduce the read to an end base (as said by Yang, left-most-read-base to count in bam file, take just one base, to avoid that one read in multiple regions) and count the reduced single base.~~
  
  - Use `-p --read2pos 5 single_paired_read1_*.bam`. Use paired-end, but only uses read 1. Reduce the read to left-most-base.


```{r}
feature_counts_mode <- data.frame(
  "flag" = c(
    "-p",
    "-p -O",
    "-p --largestOverlap", 
    "-p --read2pos 5", 
    "--read2pos 5", 
    "-p --read2pos 5 single_paired_read1_*.bam",
    
    "-p --read2pos 5 -O",
    "-p --read2pos 5 --largestOverlap"
  ),
  "interpretation" = c(
    "paired-end, ignore overlap count",
    "paired-end, assign overlap count to all regions",
    "paired-end, assign overlap count to region with largest overlap",
    "paired-end, reduce read to left-most-base",
    "single-end, reduce read to left-most-base",
    "paired-end, reduce read to left-most-base, but use only the first read",
    
    "paired-end, reduce read to left-most-base, assign overlap count to all regions",
    "paired-end, reduce read to left-most-base, assign to largest overlap"
  )
)

knitr::kable(feature_counts_mode)
```


```{r out.width="50%", fig.cap="Figure: (un)Assigned reads under various counting modes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_count_mode.pdf"), error = FALSE)
```


**Observation**

- Unassigned reads under `-p --read2pos 5 single_paired_read1_*.bam`.
  
  - These unassigned reads due to ambiguity are only for one individual.
  
  - Weirdly, if I do read counting for only this individual, there is no unassigned reads.
  
  - If I count read all individuals together and with `-R` to output the detailed (un)assignment of each read, there is no unassigned reads again. So I couldn't check exactly which reads were unassigned for this individual.
  
  - I used the above read counting results.



- Why both single-end and paired-end reads occur in one bam file?
  
  Paired-end sequencing. But those single-end reads are not aligned to ref genome.




**A few numbers - raw counts**

- For current exploratory phase, I only run chromosome 20, which was split to 64,444 1kb-segments.
  
  - 62,910 (~97.62%) segments with at least one read in one individual.
  
  - %individuals without any reads


```{r out.width="30%", fig.cap="Figure: Raw counts across segments.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_seg_count.pdf", "asset/2023/03_08_seg_count_zoom.pdf"), error = FALSE)
```


```{r out.width="30%", fig.cap="Figure: % Individuals with nonzero raw counts.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_08_perct_ind.pdf"), error = FALSE)
```


- I feature count 2337 peaks on chr20, and compared the count summary with segment-version on chr20. A few potential questions needed further understanding -

  - In featureCounts, unassigned reads due to Unassigned_Duplicate, Unassigned_NoFeatures, many Unassigned_Ambiguity.
  
  - There are many Unassigned_Ambiguity, because reads can fall between adjacent segments. Solution: use `--read2pos` to count only the left-most-base.




### QC & Normalization

- Remove segments without any reads for any individuals.

- Filter segments by proportion of samples with non-zero reads - 100%, 50%.

- Regular standardization & qqnorm way v.s. leafcutter way.


### Covariates

Temporary workaround - Use PC's of peaks.


### QTLTools

Chr20 for now. All cis-SNPs around 500kb of each segment.



## 3. Count based - Perform PCO

### Define segment groups

- Window size - 10kb

- Segment size - 1kb


```{r out.width="50%", fig.cap="Figure: Segment group size under 10kb window size across prop_nonzero (1, 0.5).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_seg_group_size.pdf"), error = FALSE)
```


**Observations** -

- #groups used for PCO (remove those groups with 1 seg)

- group size v.s. sample size (72)
  
  Group size controlled under 10, for seg_size = 1kb, window_size=10kb


- Is 1kb too wide for segment size?


### Perform PCO

- P for across prop_nonzero (1, 0.5) & compare to peak group.

- I expect seg_pco to be similar to peak_pco, as these results are from mark H3K27ac with narrow peaks.
  
  - I expect seg_pco to be powerful for marks with broad peaks.


```{r out.width="50%", fig.cap="Figure: Comparison of small p of segment group size under 10kb window size across prop_nonzero (1, 0.5).", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/03_22_plt_smallp.pdf"), error = FALSE)
```



# Feb 24 & Feb 29

## Quick summary

- Locus zoom of a region to visualize PCO and MinP associations

- Genome track by genotype



## 1. Compare p's of specific association pairs by MinP and PCO

Change the way of visualization -

```{r out.width="50%", fig.cap="Figure: To compare MinP and PCO.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_24_plt_small_p_pco_acat_methods_diag_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```



## 2. Locus zoom of (a peak group, cis region)

### Why?

Significant PCO associations, weak ACAT associations.

For follow up analysis, e.g. coloc with traits.


But since we are not comparing to ACAT associations, is this analysis still necessary? (Does it really make sense to compare with MinP?)

For coloc purpose, improve detection of mediate effects. How does it help with coloc power? or anything else?



### How?

For a peak group, cis region. Two methods: PCO & MinP.


- Issues
  
  - ~~`locuscomparer` not available to install on midway3.~~
  
  - ~~Convert SNP position to rsid.~~
  
  - **~20% SNPs no rsid?**



### Example regions

```{r out.width="30%", fig.cap="Figure: Locus compare MinP and PCO.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_24_G55137_chr20_2_peaks_0_4588_snps_10kb_.pdf"), error = FALSE)
```


- To select regions we want?


## 3. Genometracks by genotype

### Issues I ran into

- Use the new main function

- Use the wrong flag - unknown snp led to wrong genotype group

- Use the correct template
  
  `GeneralPurposeColoredByGenotype.ini`
  
  `GeneralPurposeColoredByGenotypeWithPerIndCoverage.ini`

- Correct template
  
  Change to the correct template.
  
  Minor - change the y max value to `PerGroupMaxPerInd`


### Example regions

```{r out.width="50%", fig.cap="Figure: Genome tracks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/1.pdf"), error = FALSE)
```

[Format 1](asset/2023/1.pdf)

[Format 2](asset/2023/2.pdf)


- To select regions we want?



## 4. Ideas from reading

- Define sliding windows with skip
  
  https://doi.org/10.1038/ng.2671 NA Something I learned that can be used in my cQTL work - Define sliding windows with skip by sliding the window based on both (1) sliding across at least one peak (the current way), (2) skip a gap window. Adding a gap sliding distance can decrease the degree of overlapping between two adjacent peak groups and reduce the number of tests. Or to be more precisely, use an overlap fraction.

- The idea of using overlap fraction to merge our significant peak groups.




# Feb 17

## Quick summary

- Evaluate PCO_ACAT

-  Apply PCO_ACAT to all chr's and window sizes of sliding windows with the goal to analyze data

- Thoughts & insights on previous results after reading ACAT more carefully



## 1. Evaluate PCO_ACAT

On non-overlapping windows as described in [previous progress](#non_overlapping_window).


### v.s. PCO

with the goal to see if PCO_ACAT works.
  
  - Compare P value distribution
  
```{r out.width="50%", fig.cap="Figure: To compare PCO and PCO_ACAT. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_15_plt_compare_small_p_pco_acat_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```

  - A more rigorous way to compare distributions?
  
  - Compare small p's of window sizes
  
  [Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.](asset/2023/02_15_plt_compare_small_p_pco_acat_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Compare specific association pairs
  
  [Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_15_plt_compare_small_p_pco_acat_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Computation time



### v.s. ACAT/MinP

with the goal to see if there is any improvement by PC-based method.

  - Compare P value distribution
  
```{r out.width="50%", fig.cap="Figure: To compare PCO_ACAT and ACAT?MinP. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_15_plt_small_p_pco_acat_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


  - Compare small p's of window sizes
  
  [Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.](asset/2023/02_15_plt_small_p_pco_acat_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Compare specific association pairs
  
  [Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_15_plt_small_p_pco_acat_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}

  
  - Computation time



## 2. Apply to all chr's and window sizes of (~~non-overlapping~~ / sliding windows) to analyze data

- Done.

- Computation time
  
  For $22\times9\times2$ ...



## 3. Thoughts & insgihts after read ACAT more carefully

Thoughts on previous results/observations/questions/concerns -

- Why did we observe similar p value distribution by ACAT and MinP (corrected by Bonferroni)
  
  As we discussed in ACAT paper JC, ACAT can be dominated by the very small p values.
  
  MinP corrected by Bonferroni and MinP with p values calculated by computational heavy permutation are similar.


- Why did we observe less improvements by PCO than ACAT/MinP than expected?
  
  - ACAT/MinP is not a good/common standard to compare with (as said by Yang), as (1) it is already powerful, (2) it is not what we wanted to improve on.
  
  - We should compare with univariate methods, which is commonly used and less improved and less powerful.
  
  - Not to compare the number of SNPs, as not significant biological meaning and hard to implement. Instead, we can use other ways, e.g. if improved coloc signals with traits, etc.




# Feb 08

## Quick summary

- Tested (SNP, peak group) of groups defined by non-overlapping windows.


## 1. Groups defined by non-overlapping windows {#non_overlapping_window}

### Why? (discussion on slack)

We observed many improved associations of PCO than ACAT/MinP in [previous section](#p_distribution_across_methods_and_window_sizes). One potential issue is these improved associations could possibly come from a small set of associations, due to many repetitive peaks & SNPs by sliding window, which appears to be a large set of associations.

So, we need to look into the case using non-overlapping windows, just to make sure the PCO improvement over minP is still there after avoiding repetitive counting of associations.


- Four points we discussed in Tuesday's meeting
  
  - Why coloc style and MACS2 style not work in this case?
    
    Because these two generate noncontinuous genomic regions, whereas what we need is to divide the whole genome into non-overlapping chunks.
  
  - Why would simple useage of non-overlapping windows not make sense in final version results? 
    
    Because choosing the start and end of the dividing window seems arbitrary.
  
  - It only makes sense if we want to take a rough look at PCO v.s. ACAT/MinP to avoid repetitive counting of signals in preliminary results.
  
  - To get final results, we should go back to sliding window + MACS2 merge.
    
    Calculate p-value for groups by sliding window, then merge. Maybe then test again to obtain updated p for merged group?


### How?

- Define non-overlapping windows
  
  Dividing the genomic locations starting from 0 into non-overlapping windows of a given window size.


### Results

- Compare small p's of three methods - Overall summary figures
  
  - Panel B shows the advantage of PCO persists under window size 25kb or smaller.
  
```{r out.width="50%", fig.cap="Figure: To compare three methods under non-overlapping windows. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_08_nonoverlap_window_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


- Compare small p's of three methods - Scatter plot
  
  **This is an important figure, but it's too large to show explicitly.**
  
  - For a pair of (SNP, group), PCO improves p-value than ACAT/MinP under window size 25kb or smaller.
  
  - For pair of (SNP, group) with p around 1e-5 by ACAT/MinP (i.e. the middle part), some pairs have improved p by PCO. (These pairs are likely the additionally identified signals by PCO.)
  
  - For pair of (SNP, group) with small p by ACAT/MinP (i.e. the right part) ...
  
  - PCO p in large, middle, and extreme small window sizes ...

[Figure: To compare each (SNP, group) association by three methods under non-overlapping windows. x-axis: (SNP, group) associations, with small P < 1e-5. Point is a (SNP, group) association. y-axis: -log10(small P). Color: methods. Panel: window size. These p's are from all chr20-22.](asset/2023/02_08_nonoverlap_window_plt_small_p_methods_point_H3K27AC_window_all_cis500kb_chr20-22.pdf){width="50%"}


- Compare small p's of window sizes
  
  - PCO better or ACAT/MinP worse?

```{r out.width="50%", fig.cap="Figure: To compare window sizes under non-overlapping windows. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_08_nonoverlap_window_plt_small_p_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


# Feb 01

## Quick summary

- Compare small p, instead of top p, across three methods & window sizes

- Try even more extreme window sizes

- Example associations (by R not genome tracks)


## 1. Compare methods and window sizes using small p rather than top p

### Why


### How?

- Available results
  
  Methods - ACAT, MinP, PCO.
  
  Window size - 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  Chr - 20, 21, 22.

- Small p value cut off: 1e-5
  
  For a pair of (SNP, group), keep its association for comparing  if p by at least one method (ACAT, MinP, PCO) < 1e-5.


### Results

1. Compare small p's of three methods

[See below section for updated results]

**Observation**

- Why the density line of PCO and minP under 10kb look so different from the density lines below?
  
  It's because the smoothing algorithm to estimate the line for "density" (Figure C) and "histogram" (Figure A) is different. So the two lines have subtle difference.
  
  To avoid this, I changed the visualization from using a line of histogram (Figure A) to using histogram itself (Figure B).

- Figure B shows that PCO has smaller P's than MinP under 10kb window.



2. Compare small p's of window sizes

[See below section for updated results]


## 2. Try even more extreme window sizes

### Why


### How?

- Available results

  Methods - ACAT, MinP, PCO.
  
  Window size - **1kb, 2.5kb, 5kb**, 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  Chr - 20, 21, 22.

### Results {#p_distribution_across_methods_and_window_sizes}

- Compare small p's of three methods

```{r out.width="50%", fig.cap="Figure: To compare three methods. Color: methods. Panel: window size. x-axis: -log10(small P), small P < 1e-5. y-axis: (A-B) number of (SNP, peak group),(C) Density of (SNP, peak group) with corresponding P. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```

- Compare small p's of window sizes

```{r out.width="50%", fig.cap="Figure: To compare window sizes. Color: window sizes. (A) x-axis: -log10(small P), small P < 1e-5. y-axis: density of (SNP, peak group) associations with corresponding P. (B) x-axis: -log10(small P), small P < 1e-5. y-axis: number of (SNP, peak group) associations with corresponding P. (C) Numbers of tests across window sizes. These p's are from all chr20-22.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_windows_H3K27AC_window_all_cis500kb_chr20-22.pdf"), error = FALSE)
```


- Aggregate all p values across chr's & window sizes and calculate stats: #groups, #tests

```{r out.width="40%", fig.cap="Figure: ", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_all_p_stats_H3K27AC_windowall_cis500kb_chr20-22.pdf"), error = FALSE)
```

  - Number of groups decreases as window size decreases
  
  - Number of (SNP, group) tests appears as U-shape


- Use a lower p cutoff
  
  P values lower than 1e-8, 1e-10 will be included.

```{r out.width="50%", fig.cap="Figure: LEFT: P cutoff 1e-8. RIGHT: P cutoff 1e-10.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22_pthre1e-08.pdf", "asset/2023/02_01_plt_small_p_methods_H3K27AC_window_all_cis500kb_chr20-22_pthre1e-10.pdf"), error = FALSE)
```


**Observation**



## 3. Example associations to visualize P_pco and P_acat

### Goal

"For example, pick an example where PCO improved pvalue and pick another example where PCO doesn't improve pvalue?"


- ~~sashimi plots~~

- GenometracksByGenotype - pyGenomeTracks by genotype
  
  (Not doable yet)

### Another way

- Criteria to choose (SNP, group) to visualize for PCO and ACAT
  
  - Enough large difference: -log(P_pco/P_acat) > 5
  
  - At least one weak association: max(P_pco, P_acat) > 1e-5
  
  - Non-inf values: Non-zero P_pco


- Window - 100kb; Chr - 20-22


```{r out.width="20%", fig.cap="Figure: ", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/02_01_eg_H3K27AC_window100kb_cis500kb_G58821_22-21484558-CT-C_7_0_5.pdf", "asset/2023/02_01_eg_H3K27AC_window100kb_cis500kb_G57611_21-8836656-C-CAA_32_0_-5.pdf"), error = FALSE)
```



# Jan 25

## Quick Summary

- Test peak group defined by smaller window sizes using ACAT, minP, PCO.



## 1. Try smaller window sizes

### Why?

- We observed from last week's results that, it seems that PCO's p move toward ACAT/minP p when window sizes decrease.

- Groups of smaller window sizes that have multiple peaks tend to have physically closer peaks, thus more shared genetic control.


Therefore, we wanted to check if that pattern persists under smaller window sizes. So, I tried extreme window sizes, 10kb, 25kb, 50kb.


### How?

- Window sizes
  
  10kb, 25kb, 50kb, 100kb, 260kb, 500kb.


- Test groups with size > 1
  
  Smaller window sizes can have less groups tested.


- Test overlapped cis-SNPs within 500kb of peaks


- Available results
  
  window size - 10kb, 25kb, 50kb, 100kb, 260kb, 500kb.
  
  chr - 20, 21, 22.


### Results

- Compare methods under same window size

```{r out.width="50%", fig.cap="Figure: Scatter plot of top p by three methods under same window size on chr21. x-axis: Each peak group. y-axis: -log10(P). Color show methods. Panel show window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_methods_scatter_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```


```{r out.width="50%", fig.cap="Figure: Distribution density of top p by three methods under same window size on chr21. x-axis: -log10(P). y-axis: density of peak group with corresponding P. Color show methods. Panel show window sizes. Same total number of groups within each panel.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_methods_density_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```

  We observe that PCO seems to similar or even more small p's under smaller window sizes. The question is - Is it because PCO under small windows better or ACAT/minP worse?



- Compare window sizes of same method

(more complicated as different numbers of groups tested)
  

```{r out.width="50%", fig.cap="Figure: Distribution of top p across window sizes by same method on chr21. x-axis: -log10(P). y-axis: (A) density, (B) number of peak group with corresponding P. Color show window sizes. Panel show methods. (C) Different numbers of groups (size > 1) tested for window sizes in each panel.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_25_plt_top_p_windows_density_H3K27AC_window_all_cis500kb_chr21.pdf"), error = FALSE)
```


Q - Larger window, higher proportion of small p, for ACAT/minP not pco, why?


- A fair way to compare window sizes?



- Top p of matching groups by three methods across window sizes


- Others

  - Group size tested

  - Number of cis-SNPs tested


## 2. PCO + ACAT




# Jan 18

## Quick Summary

- Compare across window sizes

- PC-based test on (SNP, peak group)



## 1. Determine window size

### Use all p not just top-p

- Compare p using ACAT and minp

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_18_plt_small_p_peak_group_density_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```


- Compare p by ACAT across window sizes (different total number of tests)

```{r out.width="60%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_window_size_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Distribution of small p under same number of peaks in group & same number of cpeaks in group

  small_p_thre <- 1e-8

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Percentage of cPeaks in group with small p under same number of peaks in group & same number of cpeaks in group

  small_p_thre <- 1e-8

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_perct_cpeak_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


- Number of groups

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_group_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```

- Number of cis-SNPs

```{r out.width="40%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_small_p_cis_snp_same_peak_H3K27AC_cis500kb.pdf"), error = FALSE)
```


## 2. Determine test

### PC-based

- phenotype

- genotype

- covaraites

  H3K27AC: 14 PCs


- Sigma
  
  Number of peaks v.s. number of samples (73)


- $\lambda>0.1$


- Available results
  
  Window size: 100kb, 250kb, 500kb.
  
  Chr: 21, 22.

- Comparison of top p across three methods

  - Scatter plot

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```
  
  - Distribution of top p

```{r out.width="30%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_density_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```

  - Top p v.s. group size

```{r out.width="80%", fig.cap="Figure: .", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_18_plt_top_p_pco_peak_group_on_num_peaks_H3K27AC_window500kb_cis500kb_chr21.pdf"), error = FALSE)
```


## 3. Compare multi-cQTLs with uni-cQTLs

After discussion on slack, we decided **not to use uni-cQTLs as a comparison metric for now**. Reasons - 

- Comparison with uni-cQTLs not necessary in the long run for biological interpretations.

- Comparison with minp is sufficient for now

- Other ways for comparison of multi-cQTLs on top of the # of significant SNPs



# Jan 11

## Quick Summary

- Make the pipeline automatic.

- Tested (SNP, peak group) by ACAT at 100kb, 250kb, 500kb window size.

- Compare multi-cQTLs across window sizes and ~~with uni-cQTLs~~.


## 1. Define peak groups under different window sizes and test (SNP, peak group)

Last time, I tested (SNP, peak group) of peak groups defined by 500kb window sizes using SNPs within 500kb of peak group.

This time, I tried various window sizes, including 100kb, 250kb, 500kb.


### How?

- Peaks are considered as a peak group using a sliding window of sizes 100kb, 250kb, 500kb.

- Use 500kb as the cis distance to search for the cis-SNPs of each individual peaks in the group, then tested the overlapped SNPs across all peaks in the group. [Note: we discussed on slack to use 500kb as cis distance for all window sizes.]


```{r out.width="40%", fig.cap="Figure: Choose cis distance for different window size.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_choose_cis_dis.jpeg"), error = FALSE)
```


- ACAT test.


### Numbers

Use a table or histogram ...


### Results

- Number of peaks in groups

```{r out.width="20%", fig.cap="Figure: Number of peaks in peak groups defined by different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_peaks_in_group_H3K27AC_window100kb.pdf", "asset/2023/01_11_peaks_in_group_H3K27AC_window250kb.pdf", "asset/2023/01_11_peaks_in_group_H3K27AC_window500kb.pdf"), error = FALSE)
```


- Number of peaks in groups colored by cPeaks (uni)

  [Note: as we discussed on slack, I used the results of cPeaks within 500kb cis distance.]

```{r out.width="30%", fig.cap="Figure: Number of peaks in peak groups defined by different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window100kb_cpeak500kb.pdf", "asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window250kb_cpeak500kb.pdf", "asset/2023/01_11_peaks_in_group_w_cqtl_H3K27AC_window500kb_cpeak500kb.pdf"), error = FALSE)
```


- Peak groups on chr

[100kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window100kb.pdf)

[250kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window250kb.pdf)

[500kb window](asset/2023/01_11_peaks_on_chr_H3K27AC_window250kb.pdf)


- Number of cPeaks in peak groups

[100kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window100kb_cpeak500kb.pdf)

[250kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window250kb_cpeak500kb.pdf)

[500kb window](asset/2023/01_11_peaks_w_cqtl_in_group_H3K27AC_window500kb_cpeak500kb.pdf)

- Distribution of the top p-value of a peak group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_density_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group v.s. number of peaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```


- Top p of a peak group v.s. number of cPeaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_at_peaks_w_cqtl_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group on chromosomal position

```{r out.width="35%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group on chromosomal position v.s number of cPeaks in the group

```{r out.width="30%", fig.cap="Figure: Distribution of top p-values across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window100kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window250kb_cis500kb.pdf", "asset/2023/01_11_plt_top_p_peak_group_manhattan_cqtl_H3K27AC_window500kb_cis500kb.pdf"), error = FALSE)
```

- Top p of a peak group v.s chromosomes

[100kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window100kb_cis500kb.pdf)

[250kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window250kb_cis500kb.pdf)

[500kb window](asset/2023/01_11_plt_top_p_peak_group_on_chr_H3K27AC_window500kb_cis500kb.pdf)


- Top p of a peak group v.s. the number of peaks in the group

[100kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window100kb_cis500kb.pdf)

[250kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window250kb_cis500kb.pdf)

[500kb window](asset/2023/01_11_plt_top_p_peak_group_on_num_peaks_H3K27AC_window500kb_cis500kb.pdf)


## 2. Compare results across window sizes

I compared the results of peak groups defined by different window sizes in terms of (1) cQTLs (2) peak groups.


### Top p-value distribution across window sizes

```{r out.width="50%", fig.cap="Figure: Top p-vaue of a peak group across window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_top_p_window_size_H3K27AC_cis500kb.pdf"), error = FALSE)
```


### Number of significant cQTLs across window sizes

- How?

  - Use 1e-10 as the uniform p-value cutoff across window sizes.
  
  - Unique cQTLs for each group


Define significant cQTLs under same cutoff, as (1) same number of peak groups, (2) same cis distance used to search for SNPs to be tested.

- But not same number of SNPs tested?


```{r out.width="30%", fig.cap="Figure: Number of cQTLs across window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_cqtl_window_size_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


### cQTLs overlap across window sizes

- Use 1e-10 as the uniform p-value cutoff across window sizes.

```{r out.width="40%", fig.cap="Figure: Overlaps among cQTLs of different window sizes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_cqtl_overlap_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


- Observations

1. Most are shared.

2. 100kb some specific cQTLs?


- Missed cQTLs v.s. distance to their target peak groups

  Question to ask - Are the missed cQTLs those which are distant to their target peak groups, therefore, were not considered for association tests? Or is it because true higher power?

```{r out.width="40%", fig.cap="Figure: Window-size-specific cQTLs v.s. their distances to target peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2023/01_11_plt_window_spec_cqtl_dist_group_H3K27AC_cis500kb_logp10.pdf"), error = FALSE)
```


### In terms of peak groups




## 3. Compare multi-cQTLs with uni-cQTLs


**Questions?**




# Dec 21

## Quick Summary

- Ran associations (by ACAT) between SNPs and peak groups using cis-window 1Mb.

- Looked at the distribution of p-values.



## 1. Update: Test a SNP and a group of adjacent peaks by ACAT

### Updates

- For each peak group, test its association across all overlapped SNPs (SNPs with cis-cQTL associations with all peaks in the group). ~~<u>**[Here I used the 100kb cis-cQTL]**</u>~~ <u>**[Use 1Mb cis-cQTL]**</u>


- For now, I only looked at the the peaks groups,
  
  - ~~where none of the peaks have significant cis-cQTLs <u>**[Here I used the 100kb cis-cQTL]**</u>~~ Run across all peak groups no matter how many significant cis-cQTLs they have.
  
  - which have more than 1 peak
  
  - of mark H3K27AC


- Except peak groups on chr1.


### Results

- Look at the distribution of top p-values of peak groups.

```{r out.width="30%", fig.cap="LEFT: Distribution of the top p-value (by ACAT and minp_adjusted) across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_density_H3K27AC.pdf"), error = FALSE)
```


- Look at the distribution of top p-values of peak groups on the size of peak groups and chromosomes.

```{r out.width="40%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_on_num_peaks_H3K27AC.pdf", "asset/2022/12_21_plt_top_p_peak_group_on_chr_H3K27AC.pdf"), error = FALSE)
```


- Distribution of top p-values on chromosomal position.

```{r out.width="60%", fig.cap="Distribution of the top p-value across peak groups on chromosomal position.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_manhattan_H3K27AC.pdf"), error = FALSE)
```


- Top p values of a peak group v.s. the number of peaks?

```{r out.width="50%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group. Color: the number of peaks in a peak group.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_peaks.pdf"), error = FALSE)
```


- Top p values of a peak group v.s. the number of peaks with cQTLs?

  - .. and a more detailed zoom-in on chromosomal position given below

```{r out.width="50%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group that have cQTLs. Color: the number of peaks in a peak group that have cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_w_cqtl.pdf"), error = FALSE)
```

```{r out.width="70%", fig.cap="A more detailed zoom-in. Top p-values across peak groups on chromosomal position, grouped and colored by #peaks with uni-cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_21_plt_top_p_peak_group_manhattan_cqtl_H3K27AC.pdf"), error = FALSE)
```


- Compare the uni-cQTLs and multi-cQTLs of a peak group




~~### Numbers

Total peak groups: 100858

Peak groups on chr1: 10038

Peak groups on chr2-chr22: 90150 (90787, 90166)


Peak groups with only 1 peak: 26458

~~



# Dec 14

## Quick Summary

- Run ACAT to test associations between (SNP, adjacent peak group) for mark H3K27AC.


## 1. cQTL of peaks with cis-window of 1Mb

[Waiting for Carlos to run this step for me.]


## 2. Adjacent peaks as peak groups

### How?

- Sliding window of length 500kb.

- Start with a peak, extend from its start position to a 500kb window, include all peaks in this window as a peak group.

- Slide to next peak.


### Look into peak groups

- Number of peak groups in total
  
  There are 100,858 peak groups in total. 
  
- Number of peaks in each group

```{r out.width="30%", fig.cap="How many peaks are included in the preak groups? x-axis: the number of peaks. y-axis: the number of peaks groups with the corresponding number of peaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_in_group_H3K27AC.pdf"), error = FALSE)
```

- For peak groups with the same number of peaks, how many peaks have cQTLs? <u>**[Here I used the 100kb cis-cQTL]**</u>

```{r out.width="30%", fig.cap="Similar figure as the above, except dividing the peak groups by the number of peaks in the group that have cQTLs. Color: the number of peaks in a peak group that have cQTLs.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_in_group_w_cqtl_H3K27AC.pdf"), error = FALSE)
```


- Number of peaks with/without cQTLs in each group <u>**[Here I used the 100kb cis-cQTL]**</u>

```{r out.width="30%", fig.cap="How many peaks within a peak group have cQTLs? x-axis: the number of peaks with cQTLs. y-axis: the number of peak groups that have corresponding cPeaks.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_peaks_w_cqtl_in_group_H3K27AC.pdf"), error = FALSE)
```


## 3. Test a SNP and a group of adjacent peaks by ACAT

### How?

- For each peak group, test its association across all overlapped SNPs (SNPs with cis-cQTL associations with all peaks in the group). ~~<u>**[Here I used the 100kb cis-cQTL]**</u>~~ <u>**[Use 1Mb cis-cQTL]**</u>


- For (peak group, SNP), test by ACAT, a method to combine p-values.
  
  - As a comparison, I also calculated the adjusted minp, which $=min\{p_{snp, peak_1}, \dots, p_{snp, peak_k}\} \times k$, where $k$ is the number of peaks in the group.


- For now, I only looked at the the peaks groups,
  
  - ~~where none of the peaks have significant cis-cQTLs <u>**[Here I used the 100kb cis-cQTL]**</u>~~ Run across all peak groups no matter how many significant cis-cQTLs they have.
  
  - which have more than 1 peak
  
  - of mark H3K27AC


### Results

- There are 25,853 peak groups considered for association test.

- 3,450 peak groups have at least one overlapped SNPs. <u>**[Here I used the 100kb cis-cQTL]**</u>

So, now I have ACAT p-values (and adjusted minp) for peak groups across their overlapped SNPs. I take the minimum p-value for a peak group across the overlapped SNPs as the top p-value for the peak group.

- Look at the distribution of top p-values of peak groups.

```{r out.width="30%", fig.cap="LEFT: Top p-value (by ACAT and minp_adjusted) across peak groups. RIGHT: Distribution of the top p-value across peak groups.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_top_p_peak_group_H3K27AC.pdf", "asset/2022/12_14_plt_top_p_peak_group_density_H3K27AC.pdf"), error = FALSE)
```

- Look at the distribution of top p-values of peak groups on the size of peak groups and chromosomes.

```{r out.width="40%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_top_p_peak_group_on_num_peaks_H3K27AC.pdf", "asset/2022/12_14_plt_top_p_peak_group_on_chr_H3K27AC.pdf"), error = FALSE)
```

- More detailed p-values for (a SNP, a peak group) for a few peak groups with significant p_acat. See more [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G56480.pdf), [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G57648.pdf), [here](asset/2022/12_14_plt_p_peak_group_H3K27AC_G57649.pdf).

```{r out.width="30%", fig.cap="Distribution of the top p-value across peak groups on, LEFT: the groups with different number of peaks. RIGHT: chromosomes.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/12_14_plt_p_peak_group_H3K27AC_G57644.pdf"), error = FALSE)
```

### Observations

- Looks like p-values by ACAT are similar to p-values by minp adjusted by Bonferroni correction.

- The minimum p-values are ~1e-6.

- Why no significant associations?
  
  - I only test ~3k peak groups that have overlapped SNPs within 100kb window. So these peak groups are very close. So, combining these peaks don't have much improvement.
  
  - If I include more peak groups (and more SNPs) that are not so close for association test, by extending 100kb cis window to 1Mb cis window, maybe there can be more significant p-values.)
  
  - Will update the numbers after Carlos sends me the 1Mb cQTL associations.



# Dec 09

## Quick Summary

- Preliminary analysis on Carlos's hQTL results.


## Carlos's analysis and results

- A few questions
  
  - Sample size - H3K27AC (78/72), H3K4ME1 (77), H3K4ME3 (78), H3K36ME3 (95)
  
  - Why use genes as phenotype for H3K36ME3 but not peaks?
  
  - For mark H3K36ME3, peak names used for `Counts.txt`, but gene names used for the other files. A conversion file?
  
  - In file `NominalPass.txt.gz`, what's the nominal p-value cutoff?


- Data of H3K27AC, H3K4ME1, H3K4ME3, and H3K36ME3 chromatin marks
  
  - ChIP-seq data for H3K27AC, H3K4ME1 and H3K4ME3 chromatin marks in 75 LCLs from Yoruba invididuals was publicly available from a study by Grubert et al (2015). 
  
  - We produced in this study the Cut&Tag data for the H3K36ME3 chromatin mark in 96 LCLs from Yoruba individuals. 


- Pre-processing
  
  - We aligned the reads from all experiments to the GRCh38 human genome using HISAT. 
  
  - Peak calling for the ChIP-seq data was performed with MACS2 for H3K27AC and H3K4ME1 (narrow peaks), and for H3K4ME3 (broad peaks). 
  
  - For each individual, quantified ChIP-seq coverage for the three marks across the peaks using featureCounts. 
  
  - After filtering for low coverage and low variance, we were left with 100858 peaks for H3K27AC, 182749 peaks for H3K4ME1, and 55769 peaks for H3K4ME3. 
  
  - H3K36ME3 is a chromatin mark associated with transcription, and it doesn’t form clearly defined peaks like the other marks. For H3K36ME3, we quantified coverage across the top expressed 14000 protein coding genes with featureCounts. The set of top expressed genes was determined with mRNA expression in LCLs from Yoruba invidivuals in RNA-seq data from the Geuvadis consortium.


- Normalization
  
  Each phenotype (peaks or genes) by individuals coverage table was normalized as follows: 
  
  - first, for each individual we normalized the raw peak or gene counts to counts per million (CPM). 
  
  - Second, for each phenotype we applied the standard normalization across all individuals. 
  
  - Finally, for each individual we applied the rank-based inverse normal transformation across all phenotypes. 


- hQTL calling
  
  - hQTLs were called using QTLTools with permutation pass and nominal pass. We used a cis window of 100 kb, and the principal components as covariates.


- Results
  
  In summary, for each of H3K27AC, H3K4ME1 and H3K4ME3 we have a set of peaks. For each of the four chromatin marks (including H3K36ME3), we have the following data:
  
  - **Raw counts**: Phenotype (peaks or gene) by individual table of raw counts.
  
  - **Normalized counts**: Phenotype by individual table of qqnorm data (normalization described above)
  
  - **Permutation pass (top hQTL-peak/gene association)**: Table with top hQTLs for each phenotype from QTLTools in permutation pass.
  
  - **Nominal pass (all hQTL-peak/gene associations within 100kb windows of the peak)**: Table with hQTLs results for each SNP within 100kb of each phenotype from QTLTools in permutation pass.





## Strong tag enriched peaks

### Look at peaks

Questions of interest:

- Length of merged peaks

- Number of sub-peaks merged into large peaks

- Distance between peaks



### Look at pQTL effects

Questions of interest:

- What is the proportion of peaks with pQTLs?

  - For mark H3K27AC , there are 105049 peaks in total. After preprocessing, 100858 peaks are left for QTL calling. **7380 peaks ( 0.07317218 ) have significant pQTLs**, under FDR < 0.05 .
  
  - For mark H3K4ME1 , there are 190250 peaks in total. After preprocessing, 182749 peaks are left for QTL calling. **4383 peaks ( 0.02398372 ) have significant pQTLs**, under FDR < 0.05 .
  
  - For mark H3K4ME3 , there are 58171 peaks in total. After preprocessing, 55769 peaks are left for QTL calling. **3246 peaks ( 0.05820438 ) have significant pQTLs**, under FDR < 0.05 .


```{r out.width="30%", fig.cap="Significant peaks of mark H3K27AC.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/1209_dis_sig_peak_H3K27AC.pdf"), error = FALSE)
```


- Length of peaks with & w.o. pQTLs

```{r out.width="50%", fig.cap="Peak length of mark H3K27AC.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("asset/2022/1209_dis_peak_len_H3K27AC.pdf"), error = FALSE)
```


**- Reads count of peaks with & w.o. pQTLs**
**- Peak enrichment (weak v.s. strong) for peaks with & w.o. pQTLs**



- What is the distribution of effect sizes for peaks (with pQTL & without pQTLs)?
  
  - Distribution of all effects
  
  - Distribution of all effects on the dimension of SNPs and peaks coordinates
  
  - Distribution of the most significant effect for each peaks across SNPs


~~- Distribution of peaks with pQTL & without pQTLs?~~


- Are peaks without pQTLs more likely to be peaks with merged sub-peaks? (Can combining multiple sub-peaks in a large peak improve power than considering the large peak as a whole?)

**- Are peaks without pQTLs more adjacent than peaks with pQTLs? (Can combining multiple adjacent peaks improve power than using individual peaks?)**




## Weak tag enriched peaks


## What type of peaks should have improved QTL calling?

## How to improve?

1. Combine two peaks

2. Combine sub-peaks for one peak


